{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Amazon-Food-w/-Graphwave\" data-toc-modified-id=\"Amazon-Food-w/-Graphwave-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Amazon Food w/ Graphwave</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-only-T-1-embedding\" data-toc-modified-id=\"Using-only-T-1-embedding-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Using only T-1 embedding</a></span></li><li><span><a href=\"#Pure-Sum\" data-toc-modified-id=\"Pure-Sum-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Pure Sum</a></span></li><li><span><a href=\"#Expotential-Sum\" data-toc-modified-id=\"Expotential-Sum-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Expotential Sum</a></span></li></ul></li><li><span><a href=\"#Amazon-Food-Weekly\" data-toc-modified-id=\"Amazon-Food-Weekly-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Amazon Food Weekly</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-only-T-1-Embedding\" data-toc-modified-id=\"Using-only-T-1-Embedding-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Using only T-1 Embedding</a></span></li><li><span><a href=\"#Pure-Sum\" data-toc-modified-id=\"Pure-Sum-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Pure Sum</a></span></li><li><span><a href=\"#Exponential-Sum\" data-toc-modified-id=\"Exponential-Sum-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Exponential Sum</a></span></li></ul></li><li><span><a href=\"#Reddit-Equal\" data-toc-modified-id=\"Reddit-Equal-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Reddit Equal</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-only-T-1-Embedding\" data-toc-modified-id=\"Using-only-T-1-Embedding-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Using only T-1 Embedding</a></span></li><li><span><a href=\"#Pure-Sum\" data-toc-modified-id=\"Pure-Sum-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Pure Sum</a></span></li><li><span><a href=\"#Exponential-Sum\" data-toc-modified-id=\"Exponential-Sum-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Exponential Sum</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import networkx as nx \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import graphwave\n",
    "from graphwave.shapes import build_graph\n",
    "from graphwave.graphwave import *\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.random.seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_features(node_emb_1, node_emb_2, operator):\n",
    "    \n",
    "    # combine two nodes' embeddings with specificed operator\n",
    "    if operator == 'Average':\n",
    "        edge = [((x + y) / 2.0) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Hadamard':\n",
    "        edge = [(x * y) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Weighted-L1':\n",
    "        edge = [abs(x - y) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Weighted-L2':\n",
    "        edge = [abs(x - y)**2 for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Concat':\n",
    "        edge = np.concatenate((node_emb_1, node_emb_2), axis=None) \n",
    "    else:\n",
    "        print(\"Generate edge features: Operator not supported\")\n",
    "        print(\"Use default operator: Weighted-L1\")\n",
    "        edge = [abs(x - y) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "        \n",
    "    return edge\n",
    "def generate_edge_features(edge_list, node_embeddings, operator):\n",
    "    edge_features_mtx = []\n",
    "    \n",
    "    # generate features for each edge in the list\n",
    "    for node_index_1, node_index_2 in edge_list:\n",
    "        node_emb_1 = node_embeddings[node_index_1]\n",
    "        node_emb_2 = node_embeddings[node_index_2]\n",
    "        \n",
    "        edge_features_mtx.append(edge_features(node_emb_1, node_emb_2, operator))\n",
    "        \n",
    "    return edge_features_mtx\n",
    "\n",
    "def generate_train_set(graph_train, num_edge_sample, node_embeddings, edge_operator,):\n",
    "    edge_list = list(graph_train.edges)\n",
    "    num_nodes = graph_train.number_of_nodes()\n",
    "    \n",
    "    train_edges = []\n",
    "    train_edges_labels = [1] * num_edge_sample + [0] * num_edge_sample\n",
    "    \n",
    "    random.seed(0)\n",
    "    \n",
    "    # sample edges with label 1 (true edges)\n",
    "    for edge_num in range(num_edge_sample):\n",
    "        rand_index = random.randint(0, len(edge_list) - 1)\n",
    "        \n",
    "        #train_edges.append(tuple(edge_list[rand_index]))\n",
    "        train_edges.append(edge_list[rand_index])\n",
    "    non_edge_num = 0\n",
    "    \n",
    "    # sample edges with label 0 (non-exist edges)\n",
    "    while(non_edge_num < num_edge_sample):\n",
    "        rand_nodes = tuple(np.random.randint(low=0,high=num_nodes, size=2))\n",
    "        \n",
    "        if rand_nodes not in edge_list:\n",
    "            train_edges.append(rand_nodes)\n",
    "            non_edge_num += 1\n",
    "\n",
    "    train_edges_features_mtx = generate_edge_features(train_edges, node_embeddings, edge_operator)\n",
    "            \n",
    "    return train_edges, train_edges_features_mtx, train_edges_labels\n",
    "\n",
    "def generate_test_set(graph_test, node_embeddings, edge_operator):\n",
    "    edge_list = graph_test.edges\n",
    "    nodes_with_edge = set()\n",
    "    \n",
    "    for edge in edge_list:\n",
    "        nodes_with_edge.add(edge[0])\n",
    "        nodes_with_edge.add(edge[1])\n",
    "    \n",
    "    num_nodes = graph_test.number_of_nodes()\n",
    "    \n",
    "    test_edges = []\n",
    "    test_edges_labels = []\n",
    "    \n",
    "    num_edge_sample = len(edge_list)\n",
    "    non_edge_num = 0 \n",
    "    # sample edges with label 0 (non-exist edges)\n",
    "    \n",
    "    while(non_edge_num < num_edge_sample):\n",
    "        rand_nodes = tuple(np.random.randint(low=0,high=num_nodes, size=2))\n",
    "        \n",
    "        if rand_nodes not in edge_list:\n",
    "            test_edges.append(rand_nodes)\n",
    "            test_edges_labels.append(0)\n",
    "            non_edge_num += 1\n",
    "        \n",
    "    for edge in edge_list:\n",
    "        test_edges.append(edge)\n",
    "        test_edges_labels.append(1)\n",
    "    '''\n",
    "    # generate all possible edges for each node with at least one edge (assume undirected edges)\n",
    "    for node_1 in nodes_with_edge:\n",
    "        for node_2 in range(num_nodes):\n",
    "            test_edges.append((node_1, node_2))\n",
    "            \n",
    "            if (node_1, node_2) in edge_list:\n",
    "                test_edges_labels.append(1)\n",
    "            else:\n",
    "                test_edges_labels.append(0)\n",
    "    '''\n",
    "    test_edges_features_mtx = generate_edge_features(test_edges, node_embeddings, edge_operator)\n",
    "    \n",
    "    return test_edges, test_edges_features_mtx, test_edges_labels\n",
    "\n",
    "def build_clf(feature_mtx, response_vec):\n",
    "   \n",
    "    logistic_regression_model = LogisticRegression(random_state = 0,max_iter=5000,solver='liblinear',verbose=1,tol=1e-6)\n",
    "    binary_clf = logistic_regression_model.fit(feature_mtx, response_vec)\n",
    "    \n",
    "    return binary_clf\n",
    "\n",
    "def pred_links(feature_mtx, LR_clf):\n",
    "    predict_edges_labels = LR_clf.predict(feature_mtx)\n",
    "    \n",
    "    return predict_edges_labels\n",
    "\n",
    "def precision_recall(predict_labels, true_labels):\n",
    "    true_positive  = false_positive = 0\n",
    "    true_negative =  false_negative = 0\n",
    "    \n",
    "    for p_label, true_label in zip(predict_labels, true_labels):\n",
    "        \n",
    "        #print(p_label,true_label)\n",
    "        if p_label == true_label and true_label == 1:\n",
    "            true_positive += 1\n",
    "        elif p_label == true_label and true_label == 0:\n",
    "            true_negative += 1\n",
    "        elif p_label != true_label and true_label == 1:\n",
    "            false_negative += 1\n",
    "        elif p_label != true_label and true_label == 0:\n",
    "            false_positive += 1\n",
    "\n",
    "    print(\"TP: \", true_positive)\n",
    "    print(\"TN: \", true_negative)\n",
    "    print(\"FP: \", false_positive)\n",
    "    print(\"FN: \", false_negative)\n",
    "    \n",
    "    precision = 0 \n",
    "    recall = 0\n",
    "    try:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        print(\"F1: {}\".format(f1))\n",
    "    except:\n",
    "        print(\"F1: Error\")\n",
    "    \n",
    "    cm = metrics.confusion_matrix(true_labels, predict_labels)\n",
    "    print(cm)\n",
    "    print(metrics.classification_report(true_labels, predict_labels))\n",
    "    map = metrics.average_precision_score(true_labels, predict_labels)\n",
    "    print('Mean Average Precision: {}'.format(map))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(true_labels, predict_labels)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print('Area Under ROC Curve: {}'.format(roc_auc))\n",
    "    \n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Food w/ Graphwave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n"
     ]
    }
   ],
   "source": [
    "#load the graphs \n",
    "with open('/z/pujat/576/data/amazon_food/amazon_food_weekly_dir.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "print(len(graphs))\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = graphs[-20:] #only interested in the last 20 monthly snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 0/19\n",
      "Completed: 1/19\n",
      "Completed: 2/19\n",
      "Completed: 3/19\n",
      "Completed: 4/19\n",
      "Completed: 5/19\n",
      "Completed: 6/19\n",
      "Completed: 7/19\n",
      "Completed: 8/19\n",
      "Completed: 9/19\n",
      "Completed: 10/19\n",
      "Completed: 11/19\n",
      "Completed: 12/19\n",
      "Completed: 13/19\n",
      "Completed: 14/19\n",
      "Completed: 15/19\n",
      "Completed: 16/19\n",
      "Completed: 17/19\n",
      "Completed: 18/19\n"
     ]
    }
   ],
   "source": [
    "chi_list = []\n",
    "heat_print_list = []\n",
    "taus_list = []\n",
    "for e, g in enumerate(graphs[:-1]): #last embedding used for link prediction\n",
    "    chi, heat_print, taus = graphwave_alg(g, np.linspace(0,128,50), taus='auto', verbose=True)\n",
    "    chi_list.append(chi)\n",
    "    heat_print_list.append(heat_print)\n",
    "    taus_list.append(taus)\n",
    "    print(\"Completed: {}/{}\".format(e,len(graphs[:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only T-1 embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_edge_sample = 400\n",
    "edge_operator = 'Average' #'Average', 'Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_embedding = np.sum(np.asarray(chi_list[0:-1]),axis=0)\n",
    "cur_embedding = np.sum(np.asarray(chi_list),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expotential Sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ BEGIN: 1 ---------------\n",
      "[LibLinear]Edge Operator: Average\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "------------ END: 1 ---------------\n",
      "------------ BEGIN: 0.9 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "------------ END: 0.9 ---------------\n",
      "------------ BEGIN: 0.5 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "------------ END: 0.5 ---------------\n",
      "------------ BEGIN: 0.3 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  0\n",
      "TN:  1278\n",
      "FP:  0\n",
      "FN:  1278\n",
      "F1: Error\n",
      "[[1278    0]\n",
      " [1278    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      1278\n",
      "           1       0.00      0.00      0.00      1278\n",
      "\n",
      "    accuracy                           0.50      2556\n",
      "   macro avg       0.25      0.50      0.33      2556\n",
      "weighted avg       0.25      0.50      0.33      2556\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "------------ END: 0.3 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "embeddings = chi_list\n",
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "for decay in [1,0.9,0.5,0.3]:\n",
    "    print(\"------------ BEGIN: {} ---------------\".format(decay))\n",
    "    exps = [math.pow(math.e , (-i * decay)) for i in range(1,len(embeddings[:-2]))]\n",
    "    exps.reverse()\n",
    "    temp_embedding = np.zeros((embeddings[0]).shape) \n",
    "    for c,e in zip(embeddings[0:-2],exps):\n",
    "         temp_embedding += e * c \n",
    "    prev_embedding = temp_embedding + embeddings[-2]\n",
    "    \n",
    "    # this is done so the last embedding has weight one. \n",
    "    cur_embedding = temp_embedding + exps[-1] * embeddings[-2] + embeddings[-1]\n",
    "    \n",
    "    for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "        try:\n",
    "            train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "            test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "            LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "            print(\"Edge Operator: {}\".format(edge_operator))\n",
    "            predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "            precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "            print('Precision: ', precision)\n",
    "            print('Recall: ', recall)\n",
    "        except:\n",
    "            print(\"Edge Operator: {} ERROR\".format(edge_operator))\n",
    "    print(\"------------ END: {} ---------------\".format(decay))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Food Weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n"
     ]
    }
   ],
   "source": [
    "#load the graphs \n",
    "#load the graphs \n",
    "with open('/z/pujat/576/data/amazon_food/amazon_food_equal_weekly_dir.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "print(len(graphs))\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = graphs[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 0/19\n",
      "Completed: 1/19\n",
      "Completed: 2/19\n",
      "Completed: 3/19\n",
      "Completed: 4/19\n",
      "Completed: 5/19\n",
      "Completed: 6/19\n",
      "Completed: 7/19\n",
      "Completed: 8/19\n",
      "Completed: 9/19\n"
     ]
    }
   ],
   "source": [
    "chi_list = []\n",
    "heat_print_list = []\n",
    "taus_list = []\n",
    "for e, g in enumerate(graphs[:-1]): #last embedding used for link prediction\n",
    "    chi, heat_print, taus = graphwave_alg(g, np.linspace(0,200,50), taus='auto', verbose=True)\n",
    "    chi_list.append(chi)\n",
    "    heat_print_list.append(heat_print)\n",
    "    taus_list.append(taus)\n",
    "    print(\"Completed: {}/{}\".format(e,len(graphs[:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only T-1 Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2','Concat']:\n",
    "    try:\n",
    "        train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "        test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)\n",
    "\n",
    "        LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "        print(\"Edge Operator: {}\".format(edge_operator))\n",
    "        predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "        precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "        print('Precision: ', precision)\n",
    "        print('Recall: ', recall)\n",
    "    except:\n",
    "        print(\"Edge Operator: {} ERROR\".format(edge_operator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_embedding = np.sum(np.asarray(chi_list[0:-1]),axis=0)\n",
    "cur_embedding = np.sum(np.asarray(chi_list),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "num_edge_sample = 400\n",
    "\n",
    "for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2','Concat']:\n",
    "\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ BEGIN: 1 ---------------\n",
      "[LibLinear]Edge Operator: Average\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "------------ END: 1 ---------------\n",
      "------------ BEGIN: 0.9 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "------------ END: 0.9 ---------------\n",
      "------------ BEGIN: 0.5 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "------------ END: 0.5 ---------------\n",
      "------------ BEGIN: 0.3 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  0\n",
      "TN:  320\n",
      "FP:  0\n",
      "FN:  320\n",
      "F1: Error\n",
      "[[320   0]\n",
      " [320   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       320\n",
      "           1       0.00      0.00      0.00       320\n",
      "\n",
      "    accuracy                           0.50       640\n",
      "   macro avg       0.25      0.50      0.33       640\n",
      "weighted avg       0.25      0.50      0.33       640\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "------------ END: 0.3 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "embeddings = chi_list\n",
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "for decay in [1,0.9,0.5,0.3]:\n",
    "    print(\"------------ BEGIN: {} ---------------\".format(decay))\n",
    "    exps = [math.pow(math.e , (-i * decay)) for i in range(1,len(embeddings[:-2]))]\n",
    "    exps.reverse()\n",
    "    temp_embedding = np.zeros((embeddings[0]).shape) \n",
    "    for c,e in zip(embeddings[0:-2],exps):\n",
    "         temp_embedding += e * c \n",
    "    prev_embedding = temp_embedding + embeddings[-2]\n",
    "    \n",
    "    # this is done so the last embedding has weight one. \n",
    "    cur_embedding = temp_embedding + exps[-1] * embeddings[-2] + embeddings[-1]\n",
    "    \n",
    "    for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2','Concat']:\n",
    "        try:\n",
    "            train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "            test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "            LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "            print(\"Edge Operator: {}\".format(edge_operator))\n",
    "            predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "            precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "            print('Precision: ', precision)\n",
    "            print('Recall: ', recall)\n",
    "        except:\n",
    "            print(\"Edge Operator: {} ERROR\".format(edge_operator))\n",
    "    print(\"------------ END: {} ---------------\".format(decay))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit Equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the graphs \n",
    "with open('/z/pujat/576/data/reddit/reddit_equal_monthly_dir.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_list = []\n",
    "heat_print_list = []\n",
    "taus_list = []\n",
    "for e, g in enumerate(graphs[:-1]): #last embedding used for link prediction\n",
    "    chi, heat_print, taus = graphwave_alg(g, np.linspace(0,200,50), taus='auto', verbose=True)\n",
    "    chi_list.append(chi)\n",
    "    heat_print_list.append(heat_print)\n",
    "    taus_list.append(taus)\n",
    "    print(\"Completed: {}/{}\".format(e,len(graphs[:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only T-1 Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_edge_sample = 400\n",
    "edge_operator = 'Average' #'Average', 'Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_embedding = np.sum(np.asarray(chi_list[0:-1]),axis=0)\n",
    "cur_embedding = np.sum(np.asarray(chi_list),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = chi_list\n",
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "for decay in [1,0.9,0.5,0.3]:\n",
    "    print(\"------------ BEGIN: {} ---------------\".format(decay))\n",
    "    exps = [math.pow(math.e , (-i * decay)) for i in range(1,len(embeddings[:-2]))]\n",
    "    exps.reverse()\n",
    "    temp_embedding = np.zeros((embeddings[0]).shape) \n",
    "    for c,e in zip(embeddings[0:-2],exps):\n",
    "         temp_embedding += e * c \n",
    "    prev_embedding = temp_embedding + embeddings[-2]\n",
    "    \n",
    "    # this is done so the last embedding has weight one. \n",
    "    cur_embedding = temp_embedding + exps[-1] * embeddings[-2] + embeddings[-1]\n",
    "    \n",
    "    for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "        try:\n",
    "            train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "            test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "            LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "            print(\"Edge Operator: {}\".format(edge_operator))\n",
    "            predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "            precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "            print('Precision: ', precision)\n",
    "            print('Recall: ', recall)\n",
    "        except:\n",
    "            print(\"Edge Operator: {} ERROR\".format(edge_operator))\n",
    "    print(\"------------ END: {} ---------------\".format(decay))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
