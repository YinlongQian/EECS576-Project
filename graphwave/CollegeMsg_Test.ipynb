{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#CollegeMsg-Monthly-w/-Graphwave\" data-toc-modified-id=\"CollegeMsg-Monthly-w/-Graphwave-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>CollegeMsg Monthly w/ Graphwave</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-only-T-1-embedding\" data-toc-modified-id=\"Using-only-T-1-embedding-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Using only T-1 embedding</a></span></li><li><span><a href=\"#Use-0...T-Embeddings\" data-toc-modified-id=\"Use-0...T-Embeddings-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Use 0...T Embeddings</a></span></li><li><span><a href=\"#Expotential-Sum\" data-toc-modified-id=\"Expotential-Sum-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Expotential Sum</a></span></li></ul></li><li><span><a href=\"#CollegeMsg-Weekly\" data-toc-modified-id=\"CollegeMsg-Weekly-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>CollegeMsg Weekly</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-only-T-1-Embedding\" data-toc-modified-id=\"Using-only-T-1-Embedding-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Using only T-1 Embedding</a></span></li><li><span><a href=\"#Pure-Sum\" data-toc-modified-id=\"Pure-Sum-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Pure Sum</a></span></li><li><span><a href=\"#Exponential-Sum\" data-toc-modified-id=\"Exponential-Sum-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Exponential Sum</a></span></li></ul></li><li><span><a href=\"#CollegeMsg-Equal-(by-Month)\" data-toc-modified-id=\"CollegeMsg-Equal-(by-Month)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>CollegeMsg Equal (by Month)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-only-T-1-Embedding\" data-toc-modified-id=\"Using-only-T-1-Embedding-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Using only T-1 Embedding</a></span></li><li><span><a href=\"#Pure-Sum\" data-toc-modified-id=\"Pure-Sum-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Pure Sum</a></span></li><li><span><a href=\"#Exponential-Sum\" data-toc-modified-id=\"Exponential-Sum-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Exponential Sum</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import networkx as nx \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import graphwave\n",
    "from graphwave.shapes import build_graph\n",
    "from graphwave.graphwave import *\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.random.seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_features(node_emb_1, node_emb_2, operator):\n",
    "    \n",
    "    # combine two nodes' embeddings with specificed operator\n",
    "    if operator == 'Average':\n",
    "        edge = [((x + y) / 2.0) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Hadamard':\n",
    "        edge = [(x * y) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Weighted-L1':\n",
    "        edge = [abs(x - y) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Weighted-L2':\n",
    "        edge = [abs(x - y)**2 for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Concat':\n",
    "        edge = np.concatenate((node_emb_1, node_emb_2), axis=None)\n",
    "    else:\n",
    "        print(\"Generate edge features: Operator not supported\")\n",
    "        print(\"Use default operator: Weighted-L1\")\n",
    "        edge = [abs(x - y) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "        \n",
    "    return edge\n",
    "def generate_edge_features(edge_list, node_embeddings, operator):\n",
    "    edge_features_mtx = []\n",
    "    \n",
    "    # generate features for each edge in the list\n",
    "    for node_index_1, node_index_2 in edge_list:\n",
    "        node_emb_1 = node_embeddings[node_index_1]\n",
    "        node_emb_2 = node_embeddings[node_index_2]\n",
    "        \n",
    "        edge_features_mtx.append(edge_features(node_emb_1, node_emb_2, operator))\n",
    "        \n",
    "    return edge_features_mtx\n",
    "\n",
    "def generate_train_set(graph_train, num_edge_sample, node_embeddings, edge_operator,):\n",
    "    edge_list = list(graph_train.edges)\n",
    "    num_nodes = graph_train.number_of_nodes()\n",
    "    \n",
    "    train_edges = []\n",
    "    train_edges_labels = [1] * num_edge_sample + [0] * num_edge_sample\n",
    "    \n",
    "    random.seed(0)\n",
    "    \n",
    "    # sample edges with label 1 (true edges)\n",
    "    for edge_num in range(num_edge_sample):\n",
    "        rand_index = random.randint(0, len(edge_list) - 1)\n",
    "        \n",
    "        #train_edges.append(tuple(edge_list[rand_index]))\n",
    "        train_edges.append(edge_list[rand_index])\n",
    "    non_edge_num = 0\n",
    "    \n",
    "    # sample edges with label 0 (non-exist edges)\n",
    "    while(non_edge_num < num_edge_sample):\n",
    "        rand_nodes = tuple(np.random.randint(low=0,high=num_nodes, size=2))\n",
    "        \n",
    "        if rand_nodes not in edge_list:\n",
    "            train_edges.append(rand_nodes)\n",
    "            non_edge_num += 1\n",
    "\n",
    "    train_edges_features_mtx = generate_edge_features(train_edges, node_embeddings, edge_operator)\n",
    "            \n",
    "    return train_edges, train_edges_features_mtx, train_edges_labels\n",
    "\n",
    "def generate_test_set(graph_test, node_embeddings, edge_operator):\n",
    "    edge_list = graph_test.edges\n",
    "    nodes_with_edge = set()\n",
    "    \n",
    "    for edge in edge_list:\n",
    "        nodes_with_edge.add(edge[0])\n",
    "        nodes_with_edge.add(edge[1])\n",
    "    \n",
    "    num_nodes = graph_test.number_of_nodes()\n",
    "    \n",
    "    test_edges = []\n",
    "    test_edges_labels = []\n",
    "    \n",
    "    num_edge_sample = len(edge_list)\n",
    "    non_edge_num = 0 \n",
    "    # sample edges with label 0 (non-exist edges)\n",
    "    \n",
    "    while(non_edge_num < num_edge_sample):\n",
    "        rand_nodes = tuple(np.random.randint(low=0,high=num_nodes, size=2))\n",
    "        \n",
    "        if rand_nodes not in edge_list:\n",
    "            test_edges.append(rand_nodes)\n",
    "            test_edges_labels.append(0)\n",
    "            non_edge_num += 1\n",
    "        \n",
    "    for edge in edge_list:\n",
    "        test_edges.append(edge)\n",
    "        test_edges_labels.append(1)\n",
    "    \n",
    "    test_edges_features_mtx = generate_edge_features(test_edges, node_embeddings, edge_operator)\n",
    "    \n",
    "    return test_edges, test_edges_features_mtx, test_edges_labels\n",
    "\n",
    "'''\n",
    "def generate_test_set(graph_test, node_embeddings, edge_operator):\n",
    "    edge_list = graph_test.edges\n",
    "    nodes_with_edge = set()\n",
    "    \n",
    "    for edge in edge_list:\n",
    "        nodes_with_edge.add(edge[0])\n",
    "        nodes_with_edge.add(edge[1])\n",
    "    \n",
    "    num_nodes = graph_test.number_of_nodes()\n",
    "    \n",
    "    test_edges = []\n",
    "    test_edges_labels = []\n",
    "    \n",
    "    # generate all possible edges for each node with at least one edge (assume undirected edges)\n",
    "    for node_1 in nodes_with_edge:\n",
    "        for node_2 in range(num_nodes):\n",
    "            test_edges.append((node_1, node_2))\n",
    "            \n",
    "            if (node_1, node_2) in edge_list:\n",
    "                test_edges_labels.append(1)\n",
    "            else:\n",
    "                test_edges_labels.append(0)\n",
    "            \n",
    "    test_edges_features_mtx = generate_edge_features(test_edges, node_embeddings, edge_operator)\n",
    "    \n",
    "    return test_edges, test_edges_features_mtx, test_edges_labels\n",
    "'''\n",
    "def build_clf(feature_mtx, response_vec):\n",
    "   \n",
    "    logistic_regression_model = LogisticRegression(random_state = 0,max_iter=5000,solver='liblinear',verbose=1,tol=1e-6)\n",
    "    binary_clf = logistic_regression_model.fit(feature_mtx, response_vec)\n",
    "    \n",
    "    return binary_clf\n",
    "\n",
    "def pred_links(feature_mtx, LR_clf):\n",
    "    predict_edges_labels = LR_clf.predict(feature_mtx)\n",
    "    \n",
    "    return predict_edges_labels\n",
    "\n",
    "def precision_recall(predict_labels, true_labels):\n",
    "    true_positive  = false_positive = 0\n",
    "    true_negative =  false_negative = 0\n",
    "    \n",
    "    for p_label, true_label in zip(predict_labels, true_labels):\n",
    "        \n",
    "        #print(p_label,true_label)\n",
    "        if p_label == true_label and true_label == 1:\n",
    "            true_positive += 1\n",
    "        elif p_label == true_label and true_label == 0:\n",
    "            true_negative += 1\n",
    "        elif p_label != true_label and true_label == 1:\n",
    "            false_negative += 1\n",
    "        elif p_label != true_label and true_label == 0:\n",
    "            false_positive += 1\n",
    "\n",
    "    print(\"TP: \", true_positive)\n",
    "    print(\"TN: \", true_negative)\n",
    "    print(\"FP: \", false_positive)\n",
    "    print(\"FN: \", false_negative)\n",
    "    \n",
    "    precision = 0 \n",
    "    recall = 0\n",
    "    try: \n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        print(\"F1: {}\".format(f1))\n",
    "    except: \n",
    "        print(\"F1 Error\")\n",
    "    \n",
    "    cm = metrics.confusion_matrix(true_labels, predict_labels)\n",
    "    print(cm)\n",
    "    print(metrics.classification_report(true_labels, predict_labels))\n",
    "    map = metrics.average_precision_score(true_labels, predict_labels)\n",
    "    print('Mean Average Precision: {}'.format(map))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(true_labels, predict_labels)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print('Area Under ROC Curve: {}'.format(roc_auc))\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CollegeMsg Monthly w/ Graphwave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the graphs \n",
    "with open('../data/CollegeMsg/Graphs_Month_MSG/msg_1_month_dir.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 0/6\n",
      "Completed: 1/6\n",
      "Completed: 2/6\n",
      "Completed: 3/6\n",
      "Completed: 4/6\n",
      "Completed: 5/6\n"
     ]
    }
   ],
   "source": [
    "chi_list = []\n",
    "heat_print_list = []\n",
    "taus_list = []\n",
    "for e, g in enumerate(graphs[:-1]): #last embedding used for link prediction\n",
    "    chi, heat_print, taus = graphwave_alg(g, np.linspace(0,200,32), taus='auto', verbose=True)\n",
    "    chi_list.append(chi)\n",
    "    heat_print_list.append(heat_print)\n",
    "    taus_list.append(taus)\n",
    "    print(\"Completed: {}/{}\".format(e,len(graphs[:-1])))\n",
    "np.save('temp_college_msg_monthly.npy', np.asarray(chi_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only T-1 embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_edge_sample = 400\n",
    "edge_operator = 'Average' #'Average', 'Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  310\n",
      "TN:  548\n",
      "FP:  42\n",
      "FN:  280\n",
      "F1: 0.6581740976645435\n",
      "[[548  42]\n",
      " [280 310]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.93      0.77       590\n",
      "           1       0.88      0.53      0.66       590\n",
      "\n",
      "    accuracy                           0.73      1180\n",
      "   macro avg       0.77      0.73      0.72      1180\n",
      "weighted avg       0.77      0.73      0.72      1180\n",
      "\n",
      "Mean Average Precision: 0.7000192604006163\n",
      "Area Under ROC Curve: 0.7271186440677966\n",
      "Precision:  0.8806818181818182\n",
      "Recall:  0.5254237288135594\n"
     ]
    }
   ],
   "source": [
    "#for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2','Concat']:\n",
    "for edge_operator in ['Concat']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use 0...T Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_embedding = np.sum(np.asarray(chi_list[0:-1]),axis=0)\n",
    "cur_embedding = np.sum(np.asarray(chi_list),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  378\n",
      "TN:  518\n",
      "FP:  72\n",
      "FN:  212\n",
      "F1: 0.7269230769230769\n",
      "[[518  72]\n",
      " [212 378]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.78       590\n",
      "           1       0.84      0.64      0.73       590\n",
      "\n",
      "    accuracy                           0.76      1180\n",
      "   macro avg       0.77      0.76      0.76      1180\n",
      "weighted avg       0.77      0.76      0.76      1180\n",
      "\n",
      "Mean Average Precision: 0.7178305084745762\n",
      "Area Under ROC Curve: 0.7593220338983051\n",
      "Precision:  0.84\n",
      "Recall:  0.6406779661016949\n"
     ]
    }
   ],
   "source": [
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "#for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "for edge_operator in ['Concat']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expotential Sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ BEGIN: 1 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  370\n",
      "TN:  532\n",
      "FP:  58\n",
      "FN:  220\n",
      "F1: 0.7269155206286838\n",
      "[[532  58]\n",
      " [220 370]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.79       590\n",
      "           1       0.86      0.63      0.73       590\n",
      "\n",
      "    accuracy                           0.76      1180\n",
      "   macro avg       0.79      0.76      0.76      1180\n",
      "weighted avg       0.79      0.76      0.76      1180\n",
      "\n",
      "Mean Average Precision: 0.7285759543798511\n",
      "Area Under ROC Curve: 0.764406779661017\n",
      "Precision:  0.8644859813084113\n",
      "Recall:  0.6271186440677966\n",
      "------------ END: 1 ---------------\n",
      "------------ BEGIN: 0.9 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  369\n",
      "TN:  551\n",
      "FP:  39\n",
      "FN:  221\n",
      "F1: 0.7394789579158317\n",
      "[[551  39]\n",
      " [221 369]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.93      0.81       590\n",
      "           1       0.90      0.63      0.74       590\n",
      "\n",
      "    accuracy                           0.78      1180\n",
      "   macro avg       0.81      0.78      0.77      1180\n",
      "weighted avg       0.81      0.78      0.77      1180\n",
      "\n",
      "Mean Average Precision: 0.7529287138584247\n",
      "Area Under ROC Curve: 0.7796610169491526\n",
      "Precision:  0.9044117647058824\n",
      "Recall:  0.6254237288135593\n",
      "------------ END: 0.9 ---------------\n",
      "------------ BEGIN: 0.5 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  381\n",
      "TN:  530\n",
      "FP:  60\n",
      "FN:  209\n",
      "F1: 0.7390882638215325\n",
      "[[530  60]\n",
      " [209 381]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.90      0.80       590\n",
      "           1       0.86      0.65      0.74       590\n",
      "\n",
      "    accuracy                           0.77      1180\n",
      "   macro avg       0.79      0.77      0.77      1180\n",
      "weighted avg       0.79      0.77      0.77      1180\n",
      "\n",
      "Mean Average Precision: 0.735022483569699\n",
      "Area Under ROC Curve: 0.7720338983050848\n",
      "Precision:  0.8639455782312925\n",
      "Recall:  0.6457627118644068\n",
      "------------ END: 0.5 ---------------\n",
      "------------ BEGIN: 0.3 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  372\n",
      "TN:  534\n",
      "FP:  56\n",
      "FN:  218\n",
      "F1: 0.730844793713163\n",
      "[[534  56]\n",
      " [218 372]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.91      0.80       590\n",
      "           1       0.87      0.63      0.73       590\n",
      "\n",
      "    accuracy                           0.77      1180\n",
      "   macro avg       0.79      0.77      0.76      1180\n",
      "weighted avg       0.79      0.77      0.76      1180\n",
      "\n",
      "Mean Average Precision: 0.7327578013622683\n",
      "Area Under ROC Curve: 0.7677966101694915\n",
      "Precision:  0.8691588785046729\n",
      "Recall:  0.6305084745762712\n",
      "------------ END: 0.3 ---------------\n"
     ]
    }
   ],
   "source": [
    "embeddings = chi_list\n",
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "for decay in [1,0.9,0.5,0.3]:\n",
    "    print(\"------------ BEGIN: {} ---------------\".format(decay))\n",
    "    exps = [math.pow(math.e , (-i * decay)) for i in range(1,len(embeddings[:-2]))]\n",
    "    exps.reverse()\n",
    "    temp_embedding = np.zeros((embeddings[0]).shape) \n",
    "    for c,e in zip(embeddings[0:-2],exps):\n",
    "         temp_embedding += e * c \n",
    "    prev_embedding = temp_embedding + embeddings[-2]\n",
    "    \n",
    "    # this is done so the last embedding has weight one. \n",
    "    cur_embedding = temp_embedding + exps[-1] * embeddings[-2] + embeddings[-1]\n",
    "    \n",
    "    #for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "    for edge_operator in ['Concat']:\n",
    "        try:\n",
    "            train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "            test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "            LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "            print(\"Edge Operator: {}\".format(edge_operator))\n",
    "            predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "            precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "            print('Precision: ', precision)\n",
    "            print('Recall: ', recall)\n",
    "        except:\n",
    "            print(\"Edge Operator: {} ERROR\".format(edge_operator))\n",
    "    print(\"------------ END: {} ---------------\".format(decay))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CollegeMsg Weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the graphs \n",
    "with open('../data/CollegeMsg/Graphs_Week_MSG/msg_1_week_dir.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 0/27\n",
      "Completed: 1/27\n",
      "Completed: 2/27\n",
      "Completed: 3/27\n",
      "Completed: 4/27\n",
      "Completed: 5/27\n",
      "Completed: 6/27\n",
      "Completed: 7/27\n",
      "Completed: 8/27\n",
      "Completed: 9/27\n",
      "Completed: 10/27\n",
      "Completed: 11/27\n",
      "Completed: 12/27\n",
      "Completed: 13/27\n",
      "Completed: 14/27\n",
      "Completed: 15/27\n",
      "Completed: 16/27\n",
      "Completed: 17/27\n",
      "Completed: 18/27\n",
      "Completed: 19/27\n",
      "Completed: 20/27\n",
      "Completed: 21/27\n",
      "Completed: 22/27\n",
      "Completed: 23/27\n",
      "Completed: 24/27\n",
      "Completed: 25/27\n",
      "Completed: 26/27\n"
     ]
    }
   ],
   "source": [
    "chi_list = []\n",
    "heat_print_list = []\n",
    "taus_list = []\n",
    "for e, g in enumerate(graphs[:-1]): #last embedding used for link prediction\n",
    "    chi, heat_print, taus = graphwave_alg(g, np.linspace(0,200,50), taus='auto', verbose=True)\n",
    "    chi_list.append(chi)\n",
    "    heat_print_list.append(heat_print)\n",
    "    taus_list.append(taus)\n",
    "    print(\"Completed: {}/{}\".format(e,len(graphs[:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only T-1 Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  11\n",
      "TN:  85\n",
      "FP:  1\n",
      "FN:  75\n",
      "F1: 0.22448979591836732\n",
      "[[85  1]\n",
      " [75 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.99      0.69        86\n",
      "           1       0.92      0.13      0.22        86\n",
      "\n",
      "    accuracy                           0.56       172\n",
      "   macro avg       0.72      0.56      0.46       172\n",
      "weighted avg       0.72      0.56      0.46       172\n",
      "\n",
      "Mean Average Precision: 0.5532945736434108\n",
      "Area Under ROC Curve: 0.5581395348837209\n",
      "Precision:  0.9166666666666666\n",
      "Recall:  0.12790697674418605\n"
     ]
    }
   ],
   "source": [
    "#for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "for edge_operator in ['Concat']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_embedding = np.sum(np.asarray(chi_list[0:-1]),axis=0)\n",
    "cur_embedding = np.sum(np.asarray(chi_list),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  669\n",
      "TN:  884\n",
      "FP:  206\n",
      "FN:  421\n",
      "F1: 0.6809160305343511\n",
      "[[884 206]\n",
      " [421 669]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74      1090\n",
      "           1       0.76      0.61      0.68      1090\n",
      "\n",
      "    accuracy                           0.71      2180\n",
      "   macro avg       0.72      0.71      0.71      2180\n",
      "weighted avg       0.72      0.71      0.71      2180\n",
      "\n",
      "Mean Average Precision: 0.6623837483617301\n",
      "Area Under ROC Curve: 0.7123853211009175\n",
      "Precision:  0.7645714285714286\n",
      "Recall:  0.6137614678899083\n"
     ]
    }
   ],
   "source": [
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "#for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "for edge_operator in ['Concat']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ BEGIN: 1 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  750\n",
      "TN:  989\n",
      "FP:  101\n",
      "FN:  340\n",
      "F1: 0.7727975270479135\n",
      "[[989 101]\n",
      " [340 750]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.91      0.82      1090\n",
      "           1       0.88      0.69      0.77      1090\n",
      "\n",
      "    accuracy                           0.80      2180\n",
      "   macro avg       0.81      0.80      0.80      2180\n",
      "weighted avg       0.81      0.80      0.80      2180\n",
      "\n",
      "Mean Average Precision: 0.7623734624133507\n",
      "Area Under ROC Curve: 0.7977064220183487\n",
      "Precision:  0.881316098707403\n",
      "Recall:  0.6880733944954128\n",
      "------------ END: 1 ---------------\n",
      "------------ BEGIN: 0.9 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  734\n",
      "TN:  997\n",
      "FP:  93\n",
      "FN:  356\n",
      "F1: 0.7657798643714137\n",
      "[[997  93]\n",
      " [356 734]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.91      0.82      1090\n",
      "           1       0.89      0.67      0.77      1090\n",
      "\n",
      "    accuracy                           0.79      2180\n",
      "   macro avg       0.81      0.79      0.79      2180\n",
      "weighted avg       0.81      0.79      0.79      2180\n",
      "\n",
      "Mean Average Precision: 0.7609709017893791\n",
      "Area Under ROC Curve: 0.7940366972477064\n",
      "Precision:  0.8875453446191052\n",
      "Recall:  0.673394495412844\n",
      "------------ END: 0.9 ---------------\n",
      "------------ BEGIN: 0.5 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  777\n",
      "TN:  968\n",
      "FP:  122\n",
      "FN:  313\n",
      "F1: 0.7812971342383108\n",
      "[[968 122]\n",
      " [313 777]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82      1090\n",
      "           1       0.86      0.71      0.78      1090\n",
      "\n",
      "    accuracy                           0.80      2180\n",
      "   macro avg       0.81      0.80      0.80      2180\n",
      "weighted avg       0.81      0.80      0.80      2180\n",
      "\n",
      "Mean Average Precision: 0.7596845628680186\n",
      "Area Under ROC Curve: 0.8004587155963303\n",
      "Precision:  0.864293659621802\n",
      "Recall:  0.7128440366972477\n",
      "------------ END: 0.5 ---------------\n",
      "------------ BEGIN: 0.3 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  758\n",
      "TN:  956\n",
      "FP:  134\n",
      "FN:  332\n",
      "F1: 0.7648839556004036\n",
      "[[956 134]\n",
      " [332 758]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.80      1090\n",
      "           1       0.85      0.70      0.76      1090\n",
      "\n",
      "    accuracy                           0.79      2180\n",
      "   macro avg       0.80      0.79      0.78      2180\n",
      "weighted avg       0.80      0.79      0.78      2180\n",
      "\n",
      "Mean Average Precision: 0.743238573250504\n",
      "Area Under ROC Curve: 0.7862385321100916\n",
      "Precision:  0.8497757847533632\n",
      "Recall:  0.6954128440366972\n",
      "------------ END: 0.3 ---------------\n"
     ]
    }
   ],
   "source": [
    "embeddings = chi_list\n",
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "for decay in [1,0.9,0.5,0.3]:\n",
    "    print(\"------------ BEGIN: {} ---------------\".format(decay))\n",
    "    exps = [math.pow(math.e , (-i * decay)) for i in range(1,len(embeddings[:-2]))]\n",
    "    exps.reverse()\n",
    "    temp_embedding = np.zeros((embeddings[0]).shape) \n",
    "    for c,e in zip(embeddings[0:-2],exps):\n",
    "         temp_embedding += e * c \n",
    "    prev_embedding = temp_embedding + embeddings[-2]\n",
    "    \n",
    "    # this is done so the last embedding has weight one. \n",
    "    cur_embedding = temp_embedding + exps[-1] * embeddings[-2] + embeddings[-1]\n",
    "    \n",
    "    #for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "    for edge_operator in ['Concat']:\n",
    "        try:\n",
    "            train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "            test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "            LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "            print(\"Edge Operator: {}\".format(edge_operator))\n",
    "            predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "            precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "            print('Precision: ', precision)\n",
    "            print('Recall: ', recall)\n",
    "        except:\n",
    "            print(\"Edge Operator: {} ERROR\".format(edge_operator))\n",
    "    print(\"------------ END: {} ---------------\".format(decay))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CollegeMsg Equal (by Month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the graphs \n",
    "with open('../data/CollegeMsg/Graphs_Equal_Edge_MSG/msg_equal_edge_dir.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 0/27\n",
      "Completed: 1/27\n",
      "Completed: 2/27\n",
      "Completed: 3/27\n",
      "Completed: 4/27\n",
      "Completed: 5/27\n",
      "Completed: 6/27\n",
      "Completed: 7/27\n",
      "Completed: 8/27\n",
      "Completed: 9/27\n",
      "Completed: 10/27\n",
      "Completed: 11/27\n",
      "Completed: 12/27\n",
      "Completed: 13/27\n",
      "Completed: 14/27\n",
      "Completed: 15/27\n",
      "Completed: 16/27\n",
      "Completed: 17/27\n",
      "Completed: 18/27\n",
      "Completed: 19/27\n",
      "Completed: 20/27\n",
      "Completed: 21/27\n",
      "Completed: 22/27\n",
      "Completed: 23/27\n",
      "Completed: 24/27\n",
      "Completed: 25/27\n",
      "Completed: 26/27\n"
     ]
    }
   ],
   "source": [
    "chi_list = []\n",
    "heat_print_list = []\n",
    "taus_list = []\n",
    "for e, g in enumerate(graphs[:-1]): #last embedding used for link prediction\n",
    "    chi, heat_print, taus = graphwave_alg(g, np.linspace(0,200,50), taus='auto', verbose=True)\n",
    "    chi_list.append(chi)\n",
    "    heat_print_list.append(heat_print)\n",
    "    taus_list.append(taus)\n",
    "    print(\"Completed: {}/{}\".format(e,len(graphs[:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only T-1 Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  691\n",
      "TN:  1006\n",
      "FP:  84\n",
      "FN:  399\n",
      "F1: 0.7410187667560322\n",
      "[[1006   84]\n",
      " [ 399  691]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.92      0.81      1090\n",
      "           1       0.89      0.63      0.74      1090\n",
      "\n",
      "    accuracy                           0.78      2180\n",
      "   macro avg       0.80      0.78      0.77      2180\n",
      "weighted avg       0.80      0.78      0.77      2180\n",
      "\n",
      "Mean Average Precision: 0.7482610239715892\n",
      "Area Under ROC Curve: 0.7784403669724771\n",
      "Precision:  0.8916129032258064\n",
      "Recall:  0.6339449541284403\n"
     ]
    }
   ],
   "source": [
    "#for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "for edge_operator in ['Concat']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_embedding = np.sum(np.asarray(chi_list[0:-1]),axis=0)\n",
    "cur_embedding = np.sum(np.asarray(chi_list),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  658\n",
      "TN:  885\n",
      "FP:  205\n",
      "FN:  432\n",
      "F1: 0.6738351254480286\n",
      "[[885 205]\n",
      " [432 658]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.81      0.74      1090\n",
      "           1       0.76      0.60      0.67      1090\n",
      "\n",
      "    accuracy                           0.71      2180\n",
      "   macro avg       0.72      0.71      0.70      2180\n",
      "weighted avg       0.72      0.71      0.70      2180\n",
      "\n",
      "Mean Average Precision: 0.6584370714490735\n",
      "Area Under ROC Curve: 0.7077981651376147\n",
      "Precision:  0.7624565469293163\n",
      "Recall:  0.6036697247706422\n"
     ]
    }
   ],
   "source": [
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "#for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "for edge_operator in ['Concat']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ BEGIN: 1 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  761\n",
      "TN:  998\n",
      "FP:  92\n",
      "FN:  329\n",
      "F1: 0.7833247555326814\n",
      "[[998  92]\n",
      " [329 761]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83      1090\n",
      "           1       0.89      0.70      0.78      1090\n",
      "\n",
      "    accuracy                           0.81      2180\n",
      "   macro avg       0.82      0.81      0.80      2180\n",
      "weighted avg       0.82      0.81      0.80      2180\n",
      "\n",
      "Mean Average Precision: 0.7737822257117352\n",
      "Area Under ROC Curve: 0.8068807339449541\n",
      "Precision:  0.8921453692848769\n",
      "Recall:  0.6981651376146789\n",
      "------------ END: 1 ---------------\n",
      "------------ BEGIN: 0.9 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  741\n",
      "TN:  989\n",
      "FP:  101\n",
      "FN:  349\n",
      "F1: 0.7670807453416149\n",
      "[[989 101]\n",
      " [349 741]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.91      0.81      1090\n",
      "           1       0.88      0.68      0.77      1090\n",
      "\n",
      "    accuracy                           0.79      2180\n",
      "   macro avg       0.81      0.79      0.79      2180\n",
      "weighted avg       0.81      0.79      0.79      2180\n",
      "\n",
      "Mean Average Precision: 0.7583625705506767\n",
      "Area Under ROC Curve: 0.7935779816513762\n",
      "Precision:  0.8800475059382423\n",
      "Recall:  0.6798165137614679\n",
      "------------ END: 0.9 ---------------\n",
      "------------ BEGIN: 0.5 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  788\n",
      "TN:  972\n",
      "FP:  118\n",
      "FN:  302\n",
      "F1: 0.7895791583166334\n",
      "[[972 118]\n",
      " [302 788]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82      1090\n",
      "           1       0.87      0.72      0.79      1090\n",
      "\n",
      "    accuracy                           0.81      2180\n",
      "   macro avg       0.82      0.81      0.81      2180\n",
      "weighted avg       0.82      0.81      0.81      2180\n",
      "\n",
      "Mean Average Precision: 0.7673106912125078\n",
      "Area Under ROC Curve: 0.8073394495412843\n",
      "Precision:  0.869757174392936\n",
      "Recall:  0.7229357798165138\n",
      "------------ END: 0.5 ---------------\n",
      "------------ BEGIN: 0.3 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  772\n",
      "TN:  970\n",
      "FP:  120\n",
      "FN:  318\n",
      "F1: 0.7790110998990918\n",
      "[[970 120]\n",
      " [318 772]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.89      0.82      1090\n",
      "           1       0.87      0.71      0.78      1090\n",
      "\n",
      "    accuracy                           0.80      2180\n",
      "   macro avg       0.81      0.80      0.80      2180\n",
      "weighted avg       0.81      0.80      0.80      2180\n",
      "\n",
      "Mean Average Precision: 0.7588472456494013\n",
      "Area Under ROC Curve: 0.7990825688073394\n",
      "Precision:  0.8654708520179372\n",
      "Recall:  0.708256880733945\n",
      "------------ END: 0.3 ---------------\n"
     ]
    }
   ],
   "source": [
    "embeddings = chi_list\n",
    "\n",
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "for decay in [1,0.9,0.5,0.3]:\n",
    "    print(\"------------ BEGIN: {} ---------------\".format(decay))\n",
    "    exps = [math.pow(math.e , (-i * decay)) for i in range(1,len(embeddings[:-2]))]\n",
    "    exps.reverse()\n",
    "    temp_embedding = np.zeros((embeddings[0]).shape) \n",
    "    for c,e in zip(embeddings[0:-2],exps):\n",
    "         temp_embedding += e * c \n",
    "    prev_embedding = temp_embedding + embeddings[-2]\n",
    "    \n",
    "    # this is done so the last embedding has weight one. \n",
    "    cur_embedding = temp_embedding + exps[-1] * embeddings[-2] + embeddings[-1]\n",
    "    \n",
    "    #for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "    for edge_operator in ['Concat']:\n",
    "        \n",
    "        try:\n",
    "            train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "            test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "            LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "            print(\"Edge Operator: {}\".format(edge_operator))\n",
    "            predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "            precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "            print('Precision: ', precision)\n",
    "            print('Recall: ', recall)\n",
    "        except:\n",
    "            print(\"Edge Operator: {} ERROR\".format(edge_operator))\n",
    "    print(\"------------ END: {} ---------------\".format(decay))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
