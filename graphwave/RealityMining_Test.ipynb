{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#RealityMining-Monthly-w/-Graphwave\" data-toc-modified-id=\"RealityMining-Monthly-w/-Graphwave-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>RealityMining Monthly w/ Graphwave</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-only-T-1-embedding\" data-toc-modified-id=\"Using-only-T-1-embedding-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Using only T-1 embedding</a></span></li><li><span><a href=\"#Use-0...T-Embeddings\" data-toc-modified-id=\"Use-0...T-Embeddings-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Use 0...T Embeddings</a></span></li></ul></li><li><span><a href=\"#RealityMining-Weekly\" data-toc-modified-id=\"RealityMining-Weekly-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>RealityMining Weekly</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-only-T-1-Embedding\" data-toc-modified-id=\"Using-only-T-1-Embedding-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Using only T-1 Embedding</a></span></li><li><span><a href=\"#Pure-Sum\" data-toc-modified-id=\"Pure-Sum-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Pure Sum</a></span></li><li><span><a href=\"#Exponential-Sum\" data-toc-modified-id=\"Exponential-Sum-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Exponential Sum</a></span></li></ul></li><li><span><a href=\"#RealityMining-Equal\" data-toc-modified-id=\"RealityMining-Equal-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>RealityMining Equal</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-only-T-1-Embedding\" data-toc-modified-id=\"Using-only-T-1-Embedding-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Using only T-1 Embedding</a></span></li><li><span><a href=\"#Pure-Sum\" data-toc-modified-id=\"Pure-Sum-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Pure Sum</a></span></li><li><span><a href=\"#Exponential-Sum\" data-toc-modified-id=\"Exponential-Sum-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Exponential Sum</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import networkx as nx \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import graphwave\n",
    "from graphwave.shapes import build_graph\n",
    "from graphwave.graphwave import *\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.random.seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_features(node_emb_1, node_emb_2, operator):\n",
    "    \n",
    "    # combine two nodes' embeddings with specificed operator\n",
    "    if operator == 'Average':\n",
    "        edge = [((x + y) / 2.0) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Hadamard':\n",
    "        edge = [(x * y) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Weighted-L1':\n",
    "        edge = [abs(x - y) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Weighted-L2':\n",
    "        edge = [abs(x - y)**2 for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Concat':\n",
    "        edge = np.concatenate((node_emb_1, node_emb_2), axis=None) \n",
    "    else:\n",
    "        print(\"Generate edge features: Operator not supported\")\n",
    "        print(\"Use default operator: Weighted-L1\")\n",
    "        edge = [abs(x - y) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "        \n",
    "    return edge\n",
    "def generate_edge_features(edge_list, node_embeddings, operator):\n",
    "    edge_features_mtx = []\n",
    "    \n",
    "    # generate features for each edge in the list\n",
    "    for node_index_1, node_index_2 in edge_list:\n",
    "        node_emb_1 = node_embeddings[node_index_1]\n",
    "        node_emb_2 = node_embeddings[node_index_2]\n",
    "        \n",
    "        edge_features_mtx.append(edge_features(node_emb_1, node_emb_2, operator))\n",
    "        \n",
    "    return edge_features_mtx\n",
    "\n",
    "def generate_train_set(graph_train, num_edge_sample, node_embeddings, edge_operator,):\n",
    "    edge_list = list(graph_train.edges)\n",
    "    num_nodes = graph_train.number_of_nodes()\n",
    "    \n",
    "    train_edges = []\n",
    "    train_edges_labels = [1] * num_edge_sample + [0] * num_edge_sample\n",
    "    \n",
    "    random.seed(0)\n",
    "    \n",
    "    # sample edges with label 1 (true edges)\n",
    "    for edge_num in range(num_edge_sample):\n",
    "        rand_index = random.randint(0, len(edge_list) - 1)\n",
    "        \n",
    "        #train_edges.append(tuple(edge_list[rand_index]))\n",
    "        train_edges.append(edge_list[rand_index])\n",
    "    non_edge_num = 0\n",
    "    \n",
    "    # sample edges with label 0 (non-exist edges)\n",
    "    while(non_edge_num < num_edge_sample):\n",
    "        rand_nodes = tuple(np.random.randint(low=0,high=num_nodes, size=2))\n",
    "        \n",
    "        if rand_nodes not in edge_list:\n",
    "            train_edges.append(rand_nodes)\n",
    "            non_edge_num += 1\n",
    "\n",
    "    train_edges_features_mtx = generate_edge_features(train_edges, node_embeddings, edge_operator)\n",
    "            \n",
    "    return train_edges, train_edges_features_mtx, train_edges_labels\n",
    "\n",
    "def generate_test_set(graph_test, node_embeddings, edge_operator):\n",
    "    edge_list = graph_test.edges\n",
    "    nodes_with_edge = set()\n",
    "    \n",
    "    for edge in edge_list:\n",
    "        nodes_with_edge.add(edge[0])\n",
    "        nodes_with_edge.add(edge[1])\n",
    "    \n",
    "    num_nodes = graph_test.number_of_nodes()\n",
    "    \n",
    "    test_edges = []\n",
    "    test_edges_labels = []\n",
    "    \n",
    "    num_edge_sample = len(edge_list)\n",
    "    non_edge_num = 0 \n",
    "    # sample edges with label 0 (non-exist edges)\n",
    "    \n",
    "    while(non_edge_num < num_edge_sample):\n",
    "        rand_nodes = tuple(np.random.randint(low=0,high=num_nodes, size=2))\n",
    "        \n",
    "        if rand_nodes not in edge_list:\n",
    "            test_edges.append(rand_nodes)\n",
    "            test_edges_labels.append(0)\n",
    "            non_edge_num += 1\n",
    "        \n",
    "    for edge in edge_list:\n",
    "        test_edges.append(edge)\n",
    "        test_edges_labels.append(1)\n",
    "    '''\n",
    "    # generate all possible edges for each node with at least one edge (assume undirected edges)\n",
    "    for node_1 in nodes_with_edge:\n",
    "        for node_2 in range(num_nodes):\n",
    "            test_edges.append((node_1, node_2))\n",
    "            \n",
    "            if (node_1, node_2) in edge_list:\n",
    "                test_edges_labels.append(1)\n",
    "            else:\n",
    "                test_edges_labels.append(0)\n",
    "    '''\n",
    "    test_edges_features_mtx = generate_edge_features(test_edges, node_embeddings, edge_operator)\n",
    "    \n",
    "    return test_edges, test_edges_features_mtx, test_edges_labels\n",
    "\n",
    "def build_clf(feature_mtx, response_vec):\n",
    "   \n",
    "    logistic_regression_model = LogisticRegression(random_state = 0,max_iter=5000,solver='liblinear',verbose=1,tol=1e-6)\n",
    "    binary_clf = logistic_regression_model.fit(feature_mtx, response_vec)\n",
    "    \n",
    "    return binary_clf\n",
    "\n",
    "def pred_links(feature_mtx, LR_clf):\n",
    "    predict_edges_labels = LR_clf.predict(feature_mtx)\n",
    "    \n",
    "    return predict_edges_labels\n",
    "\n",
    "def precision_recall(predict_labels, true_labels):\n",
    "    true_positive  = false_positive = 0\n",
    "    true_negative =  false_negative = 0\n",
    "    \n",
    "    for p_label, true_label in zip(predict_labels, true_labels):\n",
    "        \n",
    "        #print(p_label,true_label)\n",
    "        if p_label == true_label and true_label == 1:\n",
    "            true_positive += 1\n",
    "        elif p_label == true_label and true_label == 0:\n",
    "            true_negative += 1\n",
    "        elif p_label != true_label and true_label == 1:\n",
    "            false_negative += 1\n",
    "        elif p_label != true_label and true_label == 0:\n",
    "            false_positive += 1\n",
    "\n",
    "    print(\"TP: \", true_positive)\n",
    "    print(\"TN: \", true_negative)\n",
    "    print(\"FP: \", false_positive)\n",
    "    print(\"FN: \", false_negative)\n",
    "    \n",
    "    precision = recall = 0\n",
    "    try:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        print(\"F1: {}\".format(f1))\n",
    "    except:\n",
    "        print(\"F1: Error\")\n",
    "    \n",
    "    cm = metrics.confusion_matrix(true_labels, predict_labels)\n",
    "    print(cm)\n",
    "    print(metrics.classification_report(true_labels, predict_labels))\n",
    "    map = metrics.average_precision_score(true_labels, predict_labels)\n",
    "    print('Mean Average Precision: {}'.format(map))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(true_labels, predict_labels)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print('Area Under ROC Curve: {}'.format(roc_auc))\n",
    "    \n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RealityMining Monthly w/ Graphwave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the graphs \n",
    "with open('../data/RealityMining/RealityMining_VC_Monthly.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 0/10\n",
      "Completed: 1/10\n",
      "Completed: 2/10\n",
      "Completed: 3/10\n",
      "Completed: 4/10\n",
      "Completed: 5/10\n",
      "Completed: 6/10\n",
      "Completed: 7/10\n",
      "Completed: 8/10\n",
      "Completed: 9/10\n"
     ]
    }
   ],
   "source": [
    "chi_list = []\n",
    "heat_print_list = []\n",
    "taus_list = []\n",
    "for e, g in enumerate(graphs[:-1]): #last embedding used for link prediction\n",
    "    chi, heat_print, taus = graphwave_alg(g, np.linspace(0,200,50), taus='auto', verbose=True)\n",
    "    chi_list.append(chi)\n",
    "    heat_print_list.append(heat_print)\n",
    "    taus_list.append(taus)\n",
    "    print(\"Completed: {}/{}\".format(e,len(graphs[:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only T-1 embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_edge_sample = 400\n",
    "edge_operator = 'Average' #'Average', 'Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  218\n",
      "TN:  222\n",
      "FP:  0\n",
      "FN:  4\n",
      "F1: 0.9909090909090909\n",
      "[[222   0]\n",
      " [  4 218]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       222\n",
      "           1       1.00      0.98      0.99       222\n",
      "\n",
      "    accuracy                           0.99       444\n",
      "   macro avg       0.99      0.99      0.99       444\n",
      "weighted avg       0.99      0.99      0.99       444\n",
      "\n",
      "Mean Average Precision: 0.990990990990991\n",
      "Area Under ROC Curve: 0.990990990990991\n",
      "Precision:  1.0\n",
      "Recall:  0.9819819819819819\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in ['Concat']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use 0...T Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_embedding = np.sum(np.asarray(chi_list[0:-1]),axis=0)\n",
    "cur_embedding = np.sum(np.asarray(chi_list),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  222\n",
      "TN:  222\n",
      "FP:  0\n",
      "FN:  0\n",
      "F1: 1.0\n",
      "[[222   0]\n",
      " [  0 222]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       222\n",
      "           1       1.00      1.00      1.00       222\n",
      "\n",
      "    accuracy                           1.00       444\n",
      "   macro avg       1.00      1.00      1.00       444\n",
      "weighted avg       1.00      1.00      1.00       444\n",
      "\n",
      "Mean Average Precision: 1.0\n",
      "Area Under ROC Curve: 1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "#for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "for edge_operator in ['Concat']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expotential Sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ BEGIN: 1 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  220\n",
      "TN:  222\n",
      "FP:  0\n",
      "FN:  2\n",
      "F1: 0.9954751131221719\n",
      "[[222   0]\n",
      " [  2 220]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       222\n",
      "           1       1.00      0.99      1.00       222\n",
      "\n",
      "    accuracy                           1.00       444\n",
      "   macro avg       1.00      1.00      1.00       444\n",
      "weighted avg       1.00      1.00      1.00       444\n",
      "\n",
      "Mean Average Precision: 0.9954954954954955\n",
      "Area Under ROC Curve: 0.9954954954954955\n",
      "Precision:  1.0\n",
      "Recall:  0.990990990990991\n",
      "------------ END: 1 ---------------\n",
      "------------ BEGIN: 0.9 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  220\n",
      "TN:  222\n",
      "FP:  0\n",
      "FN:  2\n",
      "F1: 0.9954751131221719\n",
      "[[222   0]\n",
      " [  2 220]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       222\n",
      "           1       1.00      0.99      1.00       222\n",
      "\n",
      "    accuracy                           1.00       444\n",
      "   macro avg       1.00      1.00      1.00       444\n",
      "weighted avg       1.00      1.00      1.00       444\n",
      "\n",
      "Mean Average Precision: 0.9954954954954955\n",
      "Area Under ROC Curve: 0.9954954954954955\n",
      "Precision:  1.0\n",
      "Recall:  0.990990990990991\n",
      "------------ END: 0.9 ---------------\n",
      "------------ BEGIN: 0.5 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  220\n",
      "TN:  222\n",
      "FP:  0\n",
      "FN:  2\n",
      "F1: 0.9954751131221719\n",
      "[[222   0]\n",
      " [  2 220]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       222\n",
      "           1       1.00      0.99      1.00       222\n",
      "\n",
      "    accuracy                           1.00       444\n",
      "   macro avg       1.00      1.00      1.00       444\n",
      "weighted avg       1.00      1.00      1.00       444\n",
      "\n",
      "Mean Average Precision: 0.9954954954954955\n",
      "Area Under ROC Curve: 0.9954954954954955\n",
      "Precision:  1.0\n",
      "Recall:  0.990990990990991\n",
      "------------ END: 0.5 ---------------\n",
      "------------ BEGIN: 0.3 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  222\n",
      "TN:  221\n",
      "FP:  1\n",
      "FN:  0\n",
      "F1: 0.9977528089887641\n",
      "[[221   1]\n",
      " [  0 222]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       222\n",
      "           1       1.00      1.00      1.00       222\n",
      "\n",
      "    accuracy                           1.00       444\n",
      "   macro avg       1.00      1.00      1.00       444\n",
      "weighted avg       1.00      1.00      1.00       444\n",
      "\n",
      "Mean Average Precision: 0.9955156950672646\n",
      "Area Under ROC Curve: 0.9977477477477478\n",
      "Precision:  0.9955156950672646\n",
      "Recall:  1.0\n",
      "------------ END: 0.3 ---------------\n"
     ]
    }
   ],
   "source": [
    "embeddings = chi_list\n",
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "for decay in [1,0.9,0.5,0.3]:\n",
    "    print(\"------------ BEGIN: {} ---------------\".format(decay))\n",
    "    exps = [math.pow(math.e , (-i * decay)) for i in range(1,len(embeddings[:-2]))]\n",
    "    exps.reverse()\n",
    "    temp_embedding = np.zeros((embeddings[0]).shape) \n",
    "    for c,e in zip(embeddings[0:-2],exps):\n",
    "         temp_embedding += e * c \n",
    "    prev_embedding = temp_embedding + embeddings[-2]\n",
    "    \n",
    "    # this is done so the last embedding has weight one. \n",
    "    cur_embedding = temp_embedding + exps[-1] * embeddings[-2] + embeddings[-1]\n",
    "    \n",
    "    #for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "    for edge_operator in ['Concat']:\n",
    "        try:\n",
    "            train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "            test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "            LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "            print(\"Edge Operator: {}\".format(edge_operator))\n",
    "            predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "            precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "            print('Precision: ', precision)\n",
    "            print('Recall: ', recall)\n",
    "        except:\n",
    "            print(\"Edge Operator: {} ERROR\".format(edge_operator))\n",
    "    print(\"------------ END: {} ---------------\".format(decay))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RealityMining Weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the graphs \n",
    "with open('../data/RealityMining/RealityMining_VC_Weekly.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 0/49\n",
      "Completed: 1/49\n",
      "Completed: 2/49\n",
      "Completed: 3/49\n",
      "Completed: 4/49\n",
      "Completed: 5/49\n",
      "Completed: 6/49\n",
      "Completed: 7/49\n",
      "Completed: 8/49\n",
      "Completed: 9/49\n",
      "Completed: 10/49\n",
      "Completed: 11/49\n",
      "Completed: 12/49\n",
      "Completed: 13/49\n",
      "Completed: 14/49\n",
      "Completed: 15/49\n",
      "Completed: 16/49\n",
      "Completed: 17/49\n",
      "Completed: 18/49\n",
      "Completed: 19/49\n",
      "Completed: 20/49\n",
      "Completed: 21/49\n",
      "Completed: 22/49\n",
      "Completed: 23/49\n",
      "Completed: 24/49\n",
      "Completed: 25/49\n",
      "Completed: 26/49\n",
      "Completed: 27/49\n",
      "Completed: 28/49\n",
      "Completed: 35/49\n",
      "Completed: 36/49\n",
      "Completed: 37/49\n",
      "Completed: 38/49\n",
      "Completed: 39/49\n",
      "Completed: 40/49\n",
      "Completed: 41/49\n",
      "Completed: 42/49\n",
      "Completed: 43/49\n",
      "Completed: 44/49\n",
      "Completed: 45/49\n",
      "Completed: 46/49\n",
      "Completed: 47/49\n",
      "Completed: 48/49\n"
     ]
    }
   ],
   "source": [
    "chi_list = []\n",
    "heat_print_list = []\n",
    "taus_list = []\n",
    "for e, g in enumerate(graphs[:-1]): #last embedding used for link prediction\n",
    "    chi, heat_print, taus = graphwave_alg(g, np.linspace(0,200,50), taus='auto', verbose=True)\n",
    "    chi_list.append(chi)\n",
    "    heat_print_list.append(heat_print)\n",
    "    taus_list.append(taus)\n",
    "    print(\"Completed: {}/{}\".format(e,len(graphs[:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only T-1 Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  0\n",
      "TN:  28\n",
      "FP:  0\n",
      "FN:  28\n",
      "F1: Error\n",
      "[[28  0]\n",
      " [28  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        28\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.50        56\n",
      "   macro avg       0.25      0.50      0.33        56\n",
      "weighted avg       0.25      0.50      0.33        56\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "for edge_operator in ['Concat']:\n",
    "    try:\n",
    "        train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "        test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)\n",
    "\n",
    "        LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "        print(\"Edge Operator: {}\".format(edge_operator))\n",
    "        predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "        precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "        print('Precision: ', precision)\n",
    "        print('Recall: ', recall)\n",
    "    except:\n",
    "        print(\"Edge Operator: {} ERROR\".format(edge_operator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_embedding = np.sum(np.asarray(chi_list[0:-1]),axis=0)\n",
    "cur_embedding = np.sum(np.asarray(chi_list),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  28\n",
      "TN:  28\n",
      "FP:  0\n",
      "FN:  0\n",
      "F1: 1.0\n",
      "[[28  0]\n",
      " [ 0 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        28\n",
      "           1       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        56\n",
      "   macro avg       1.00      1.00      1.00        56\n",
      "weighted avg       1.00      1.00      1.00        56\n",
      "\n",
      "Mean Average Precision: 1.0\n",
      "Area Under ROC Curve: 1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "#for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "for edge_operator in ['Concat']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ BEGIN: 1 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  0\n",
      "TN:  28\n",
      "FP:  0\n",
      "FN:  28\n",
      "F1: Error\n",
      "[[28  0]\n",
      " [28  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        28\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.50        56\n",
      "   macro avg       0.25      0.50      0.33        56\n",
      "weighted avg       0.25      0.50      0.33        56\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "------------ END: 1 ---------------\n",
      "------------ BEGIN: 0.9 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  0\n",
      "TN:  28\n",
      "FP:  0\n",
      "FN:  28\n",
      "F1: Error\n",
      "[[28  0]\n",
      " [28  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        28\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.50        56\n",
      "   macro avg       0.25      0.50      0.33        56\n",
      "weighted avg       0.25      0.50      0.33        56\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "------------ END: 0.9 ---------------\n",
      "------------ BEGIN: 0.5 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/z/pujat/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  28\n",
      "TN:  28\n",
      "FP:  0\n",
      "FN:  0\n",
      "F1: 1.0\n",
      "[[28  0]\n",
      " [ 0 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        28\n",
      "           1       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        56\n",
      "   macro avg       1.00      1.00      1.00        56\n",
      "weighted avg       1.00      1.00      1.00        56\n",
      "\n",
      "Mean Average Precision: 1.0\n",
      "Area Under ROC Curve: 1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "------------ END: 0.5 ---------------\n",
      "------------ BEGIN: 0.3 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  28\n",
      "TN:  28\n",
      "FP:  0\n",
      "FN:  0\n",
      "F1: 1.0\n",
      "[[28  0]\n",
      " [ 0 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        28\n",
      "           1       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        56\n",
      "   macro avg       1.00      1.00      1.00        56\n",
      "weighted avg       1.00      1.00      1.00        56\n",
      "\n",
      "Mean Average Precision: 1.0\n",
      "Area Under ROC Curve: 1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "------------ END: 0.3 ---------------\n"
     ]
    }
   ],
   "source": [
    "embeddings = chi_list\n",
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "for decay in [1,0.9,0.5,0.3]:\n",
    "    print(\"------------ BEGIN: {} ---------------\".format(decay))\n",
    "    exps = [math.pow(math.e , (-i * decay)) for i in range(1,len(embeddings[:-2]))]\n",
    "    exps.reverse()\n",
    "    temp_embedding = np.zeros((embeddings[0]).shape) \n",
    "    for c,e in zip(embeddings[0:-2],exps):\n",
    "         temp_embedding += e * c \n",
    "    prev_embedding = temp_embedding + embeddings[-2]\n",
    "    \n",
    "    # this is done so the last embedding has weight one. \n",
    "    cur_embedding = temp_embedding + exps[-1] * embeddings[-2] + embeddings[-1]\n",
    "    \n",
    "    #for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "    for edge_operator in ['Concat']:\n",
    "        try:\n",
    "            train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "            test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "            LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "            print(\"Edge Operator: {}\".format(edge_operator))\n",
    "            predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "            precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "            print('Precision: ', precision)\n",
    "            print('Recall: ', recall)\n",
    "        except:\n",
    "            print(\"Edge Operator: {} ERROR\".format(edge_operator))\n",
    "    print(\"------------ END: {} ---------------\".format(decay))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RealityMining Equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the graphs \n",
    "with open('../data/RealityMining/RM_equal_num_edges_snapshots.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 0/50\n",
      "Completed: 1/50\n",
      "Completed: 2/50\n",
      "Completed: 3/50\n",
      "Completed: 4/50\n",
      "Completed: 5/50\n",
      "Completed: 6/50\n",
      "Completed: 7/50\n",
      "Completed: 8/50\n",
      "Completed: 9/50\n",
      "Completed: 10/50\n",
      "Completed: 11/50\n",
      "Completed: 12/50\n",
      "Completed: 13/50\n",
      "Completed: 14/50\n",
      "Completed: 15/50\n",
      "Completed: 16/50\n",
      "Completed: 17/50\n",
      "Completed: 18/50\n",
      "Completed: 19/50\n",
      "Completed: 20/50\n",
      "Completed: 21/50\n",
      "Completed: 22/50\n",
      "Completed: 23/50\n",
      "Completed: 24/50\n",
      "Completed: 25/50\n",
      "Completed: 26/50\n",
      "Completed: 27/50\n",
      "Completed: 28/50\n",
      "Completed: 29/50\n",
      "Completed: 30/50\n",
      "Completed: 31/50\n",
      "Completed: 32/50\n",
      "Completed: 33/50\n",
      "Completed: 34/50\n",
      "Completed: 35/50\n",
      "Completed: 36/50\n",
      "Completed: 37/50\n",
      "Completed: 38/50\n",
      "Completed: 39/50\n",
      "Completed: 40/50\n",
      "Completed: 41/50\n",
      "Completed: 42/50\n",
      "Completed: 43/50\n",
      "Completed: 44/50\n",
      "Completed: 45/50\n",
      "Completed: 46/50\n",
      "Completed: 47/50\n",
      "Completed: 48/50\n",
      "Completed: 49/50\n"
     ]
    }
   ],
   "source": [
    "chi_list = []\n",
    "heat_print_list = []\n",
    "taus_list = []\n",
    "for e, g in enumerate(graphs[:-1]): #last embedding used for link prediction\n",
    "    chi, heat_print, taus = graphwave_alg(g, np.linspace(0,200,50), taus='auto', verbose=True)\n",
    "    chi_list.append(chi)\n",
    "    heat_print_list.append(heat_print)\n",
    "    taus_list.append(taus)\n",
    "    print(\"Completed: {}/{}\".format(e,len(graphs[:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only T-1 Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  320\n",
      "TN:  304\n",
      "FP:  18\n",
      "FN:  2\n",
      "F1: 0.9696969696969696\n",
      "[[304  18]\n",
      " [  2 320]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97       322\n",
      "           1       0.95      0.99      0.97       322\n",
      "\n",
      "    accuracy                           0.97       644\n",
      "   macro avg       0.97      0.97      0.97       644\n",
      "weighted avg       0.97      0.97      0.97       644\n",
      "\n",
      "Mean Average Precision: 0.9439707449740895\n",
      "Area Under ROC Curve: 0.968944099378882\n",
      "Precision:  0.9467455621301775\n",
      "Recall:  0.9937888198757764\n"
     ]
    }
   ],
   "source": [
    "#for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "for edge_operator in ['Concat']:\n",
    "    try:\n",
    "        train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "        test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)\n",
    "\n",
    "        LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "        print(\"Edge Operator: {}\".format(edge_operator))\n",
    "        predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "        precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "        print('Precision: ', precision)\n",
    "        print('Recall: ', recall)\n",
    "    except:\n",
    "        print(\"Edge Operator: {} ERROR\".format(edge_operator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_embedding = np.sum(np.asarray(chi_list[0:-1]),axis=0)\n",
    "cur_embedding = np.sum(np.asarray(chi_list),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  322\n",
      "TN:  321\n",
      "FP:  1\n",
      "FN:  0\n",
      "F1: 0.9984496124031007\n",
      "[[321   1]\n",
      " [  0 322]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       322\n",
      "           1       1.00      1.00      1.00       322\n",
      "\n",
      "    accuracy                           1.00       644\n",
      "   macro avg       1.00      1.00      1.00       644\n",
      "weighted avg       1.00      1.00      1.00       644\n",
      "\n",
      "Mean Average Precision: 0.9969040247678018\n",
      "Area Under ROC Curve: 0.9984472049689441\n",
      "Precision:  0.9969040247678018\n",
      "Recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "#for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "for edge_operator in ['Concat']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ BEGIN: 1 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  256\n",
      "TN:  316\n",
      "FP:  6\n",
      "FN:  66\n",
      "F1: 0.8767123287671231\n",
      "[[316   6]\n",
      " [ 66 256]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.98      0.90       322\n",
      "           1       0.98      0.80      0.88       322\n",
      "\n",
      "    accuracy                           0.89       644\n",
      "   macro avg       0.90      0.89      0.89       644\n",
      "weighted avg       0.90      0.89      0.89       644\n",
      "\n",
      "Mean Average Precision: 0.8793087098762504\n",
      "Area Under ROC Curve: 0.888198757763975\n",
      "Precision:  0.9770992366412213\n",
      "Recall:  0.7950310559006211\n",
      "------------ END: 1 ---------------\n",
      "------------ BEGIN: 0.9 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  251\n",
      "TN:  319\n",
      "FP:  3\n",
      "FN:  71\n",
      "F1: 0.8715277777777778\n",
      "[[319   3]\n",
      " [ 71 251]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90       322\n",
      "           1       0.99      0.78      0.87       322\n",
      "\n",
      "    accuracy                           0.89       644\n",
      "   macro avg       0.90      0.89      0.88       644\n",
      "weighted avg       0.90      0.89      0.88       644\n",
      "\n",
      "Mean Average Precision: 0.8805448232014477\n",
      "Area Under ROC Curve: 0.8850931677018634\n",
      "Precision:  0.9881889763779528\n",
      "Recall:  0.7795031055900621\n",
      "------------ END: 0.9 ---------------\n",
      "------------ BEGIN: 0.5 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  313\n",
      "TN:  321\n",
      "FP:  1\n",
      "FN:  9\n",
      "F1: 0.9842767295597485\n",
      "[[321   1]\n",
      " [  9 313]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       322\n",
      "           1       1.00      0.97      0.98       322\n",
      "\n",
      "    accuracy                           0.98       644\n",
      "   macro avg       0.98      0.98      0.98       644\n",
      "weighted avg       0.98      0.98      0.98       644\n",
      "\n",
      "Mean Average Precision: 0.9829291450725957\n",
      "Area Under ROC Curve: 0.9844720496894411\n",
      "Precision:  0.9968152866242038\n",
      "Recall:  0.9720496894409938\n",
      "------------ END: 0.5 ---------------\n",
      "------------ BEGIN: 0.3 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  320\n",
      "TN:  318\n",
      "FP:  4\n",
      "FN:  2\n",
      "F1: 0.9907120743034055\n",
      "[[318   4]\n",
      " [  2 320]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       322\n",
      "           1       0.99      0.99      0.99       322\n",
      "\n",
      "    accuracy                           0.99       644\n",
      "   macro avg       0.99      0.99      0.99       644\n",
      "weighted avg       0.99      0.99      0.99       644\n",
      "\n",
      "Mean Average Precision: 0.984625412161644\n",
      "Area Under ROC Curve: 0.9906832298136646\n",
      "Precision:  0.9876543209876543\n",
      "Recall:  0.9937888198757764\n",
      "------------ END: 0.3 ---------------\n"
     ]
    }
   ],
   "source": [
    "embeddings = chi_list\n",
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "for decay in [1,0.9,0.5,0.3]:\n",
    "    print(\"------------ BEGIN: {} ---------------\".format(decay))\n",
    "    exps = [math.pow(math.e , (-i * decay)) for i in range(1,len(embeddings[:-2]))]\n",
    "    exps.reverse()\n",
    "    temp_embedding = np.zeros((embeddings[0]).shape) \n",
    "    for c,e in zip(embeddings[0:-2],exps):\n",
    "         temp_embedding += e * c \n",
    "    prev_embedding = temp_embedding + embeddings[-2]\n",
    "    \n",
    "    # this is done so the last embedding has weight one. \n",
    "    cur_embedding = temp_embedding + exps[-1] * embeddings[-2] + embeddings[-1]\n",
    "    \n",
    "    #for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "    for edge_operator in ['Concat']:\n",
    "        try:\n",
    "            train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "            test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "            LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "            print(\"Edge Operator: {}\".format(edge_operator))\n",
    "            predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "            precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "            print('Precision: ', precision)\n",
    "            print('Recall: ', recall)\n",
    "        except:\n",
    "            print(\"Edge Operator: {} ERROR\".format(edge_operator))\n",
    "    print(\"------------ END: {} ---------------\".format(decay))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
