{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Email-Monthly-w/-Graphwave\" data-toc-modified-id=\"Email-Monthly-w/-Graphwave-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Email Monthly w/ Graphwave</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-only-T-1-embedding\" data-toc-modified-id=\"Using-only-T-1-embedding-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Using only T-1 embedding</a></span></li><li><span><a href=\"#Pure-Sum\" data-toc-modified-id=\"Pure-Sum-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Pure Sum</a></span></li><li><span><a href=\"#Expotential-Sum\" data-toc-modified-id=\"Expotential-Sum-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Expotential Sum</a></span></li></ul></li><li><span><a href=\"#Email-Weekly\" data-toc-modified-id=\"Email-Weekly-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Email Weekly</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-only-T-1-Embedding\" data-toc-modified-id=\"Using-only-T-1-Embedding-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Using only T-1 Embedding</a></span></li><li><span><a href=\"#Pure-Sum\" data-toc-modified-id=\"Pure-Sum-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Pure Sum</a></span></li><li><span><a href=\"#Exponential-Sum\" data-toc-modified-id=\"Exponential-Sum-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Exponential Sum</a></span></li></ul></li><li><span><a href=\"#Email-Equal-(weekly)\" data-toc-modified-id=\"Email-Equal-(weekly)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Email Equal (weekly)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-only-T-1-Embedding\" data-toc-modified-id=\"Using-only-T-1-Embedding-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Using only T-1 Embedding</a></span></li><li><span><a href=\"#Pure-Sum\" data-toc-modified-id=\"Pure-Sum-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Pure Sum</a></span></li><li><span><a href=\"#Exponential-Sum\" data-toc-modified-id=\"Exponential-Sum-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Exponential Sum</a></span></li></ul></li><li><span><a href=\"#Email-Equal(Monthly)\" data-toc-modified-id=\"Email-Equal(Monthly)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Email Equal(Monthly)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Using-only-T-1-Embedding\" data-toc-modified-id=\"Using-only-T-1-Embedding-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Using only T-1 Embedding</a></span></li><li><span><a href=\"#Pure-Sum\" data-toc-modified-id=\"Pure-Sum-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Pure Sum</a></span></li><li><span><a href=\"#Exponential-Sum\" data-toc-modified-id=\"Exponential-Sum-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Exponential Sum</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import networkx as nx \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import graphwave\n",
    "from graphwave.shapes import build_graph\n",
    "from graphwave.graphwave import *\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.random.seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_features(node_emb_1, node_emb_2, operator):\n",
    "    \n",
    "    # combine two nodes' embeddings with specificed operator\n",
    "    if operator == 'Average':\n",
    "        edge = [((x + y) / 2.0) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Hadamard':\n",
    "        edge = [(x * y) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Weighted-L1':\n",
    "        edge = [abs(x - y) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Weighted-L2':\n",
    "        edge = [abs(x - y)**2 for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Concat':\n",
    "        edge = np.concatenate((node_emb_1, node_emb_2), axis=None) \n",
    "    else:\n",
    "        print(\"Generate edge features: Operator not supported\")\n",
    "        print(\"Use default operator: Weighted-L1\")\n",
    "        edge = [abs(x - y) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "        \n",
    "    return edge\n",
    "def generate_edge_features(edge_list, node_embeddings, operator):\n",
    "    edge_features_mtx = []\n",
    "    \n",
    "    # generate features for each edge in the list\n",
    "    for node_index_1, node_index_2 in edge_list:\n",
    "        node_emb_1 = node_embeddings[node_index_1]\n",
    "        node_emb_2 = node_embeddings[node_index_2]\n",
    "        \n",
    "        edge_features_mtx.append(edge_features(node_emb_1, node_emb_2, operator))\n",
    "        \n",
    "    return edge_features_mtx\n",
    "\n",
    "def generate_train_set(graph_train, num_edge_sample, node_embeddings, edge_operator,):\n",
    "    edge_list = list(graph_train.edges)\n",
    "    num_nodes = graph_train.number_of_nodes()\n",
    "    \n",
    "    train_edges = []\n",
    "    train_edges_labels = [1] * num_edge_sample + [0] * num_edge_sample\n",
    "    \n",
    "    random.seed(0)\n",
    "    \n",
    "    # sample edges with label 1 (true edges)\n",
    "    for edge_num in range(num_edge_sample):\n",
    "        rand_index = random.randint(0, len(edge_list) - 1)\n",
    "        \n",
    "        #train_edges.append(tuple(edge_list[rand_index]))\n",
    "        train_edges.append(edge_list[rand_index])\n",
    "    non_edge_num = 0\n",
    "    \n",
    "    # sample edges with label 0 (non-exist edges)\n",
    "    while(non_edge_num < num_edge_sample):\n",
    "        rand_nodes = tuple(np.random.randint(low=0,high=num_nodes, size=2))\n",
    "        \n",
    "        if rand_nodes not in edge_list:\n",
    "            train_edges.append(rand_nodes)\n",
    "            non_edge_num += 1\n",
    "\n",
    "    train_edges_features_mtx = generate_edge_features(train_edges, node_embeddings, edge_operator)\n",
    "            \n",
    "    return train_edges, train_edges_features_mtx, train_edges_labels\n",
    "\n",
    "def generate_test_set(graph_test, node_embeddings, edge_operator):\n",
    "    edge_list = graph_test.edges\n",
    "    nodes_with_edge = set()\n",
    "    \n",
    "    for edge in edge_list:\n",
    "        nodes_with_edge.add(edge[0])\n",
    "        nodes_with_edge.add(edge[1])\n",
    "    \n",
    "    num_nodes = graph_test.number_of_nodes()\n",
    "    \n",
    "    test_edges = []\n",
    "    test_edges_labels = []\n",
    "    \n",
    "    num_edge_sample = len(edge_list)\n",
    "    non_edge_num = 0 \n",
    "    # sample edges with label 0 (non-exist edges)\n",
    "    \n",
    "    while(non_edge_num < num_edge_sample):\n",
    "        rand_nodes = tuple(np.random.randint(low=0,high=num_nodes, size=2))\n",
    "        \n",
    "        if rand_nodes not in edge_list:\n",
    "            test_edges.append(rand_nodes)\n",
    "            test_edges_labels.append(0)\n",
    "            non_edge_num += 1\n",
    "        \n",
    "    for edge in edge_list:\n",
    "        test_edges.append(edge)\n",
    "        test_edges_labels.append(1)\n",
    "    '''\n",
    "    # generate all possible edges for each node with at least one edge (assume undirected edges)\n",
    "    for node_1 in nodes_with_edge:\n",
    "        for node_2 in range(num_nodes):\n",
    "            test_edges.append((node_1, node_2))\n",
    "            \n",
    "            if (node_1, node_2) in edge_list:\n",
    "                test_edges_labels.append(1)\n",
    "            else:\n",
    "                test_edges_labels.append(0)\n",
    "    '''\n",
    "    test_edges_features_mtx = generate_edge_features(test_edges, node_embeddings, edge_operator)\n",
    "    \n",
    "    return test_edges, test_edges_features_mtx, test_edges_labels\n",
    "\n",
    "def build_clf(feature_mtx, response_vec):\n",
    "   \n",
    "    logistic_regression_model = LogisticRegression(random_state = 0,max_iter=5000,solver='liblinear',verbose=1,tol=1e-6)\n",
    "    binary_clf = logistic_regression_model.fit(feature_mtx, response_vec)\n",
    "    \n",
    "    return binary_clf\n",
    "\n",
    "def pred_links(feature_mtx, LR_clf):\n",
    "    predict_edges_labels = LR_clf.predict(feature_mtx)\n",
    "    \n",
    "    return predict_edges_labels\n",
    "\n",
    "def precision_recall(predict_labels, true_labels):\n",
    "    true_positive  = false_positive = 0\n",
    "    true_negative =  false_negative = 0\n",
    "    \n",
    "    for p_label, true_label in zip(predict_labels, true_labels):\n",
    "        \n",
    "        #print(p_label,true_label)\n",
    "        if p_label == true_label and true_label == 1:\n",
    "            true_positive += 1\n",
    "        elif p_label == true_label and true_label == 0:\n",
    "            true_negative += 1\n",
    "        elif p_label != true_label and true_label == 1:\n",
    "            false_negative += 1\n",
    "        elif p_label != true_label and true_label == 0:\n",
    "            false_positive += 1\n",
    "\n",
    "    print(\"TP: \", true_positive)\n",
    "    print(\"TN: \", true_negative)\n",
    "    print(\"FP: \", false_positive)\n",
    "    print(\"FN: \", false_negative)\n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "    try:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        print(\"F1: {}\".format(f1))\n",
    "    except:\n",
    "        print(\"F1: Error\")\n",
    "    \n",
    "    cm = metrics.confusion_matrix(true_labels, predict_labels)\n",
    "    print(cm)\n",
    "    print(metrics.classification_report(true_labels, predict_labels))\n",
    "    map = metrics.average_precision_score(true_labels, predict_labels)\n",
    "    print('Mean Average Precision: {}'.format(map))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(true_labels, predict_labels)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print('Area Under ROC Curve: {}'.format(roc_auc))\n",
    "    \n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email Monthly w/ Graphwave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the graphs \n",
    "with open('/z/pujat/576/data/email_eu/email_1_month_dir.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 0/16\n",
      "Completed: 1/16\n",
      "Completed: 2/16\n",
      "Completed: 3/16\n",
      "Completed: 4/16\n",
      "Completed: 5/16\n",
      "Completed: 6/16\n",
      "Completed: 7/16\n",
      "Completed: 8/16\n",
      "Completed: 9/16\n",
      "Completed: 10/16\n",
      "Completed: 11/16\n",
      "Completed: 12/16\n",
      "Completed: 13/16\n",
      "Completed: 14/16\n",
      "Completed: 15/16\n"
     ]
    }
   ],
   "source": [
    "chi_list = []\n",
    "heat_print_list = []\n",
    "taus_list = []\n",
    "for e, g in enumerate(graphs[:-1]): #last embedding used for link prediction\n",
    "    chi, heat_print, taus = graphwave_alg(g, np.linspace(0,200,32), taus='auto', verbose=True)\n",
    "    chi_list.append(chi)\n",
    "    heat_print_list.append(heat_print)\n",
    "    taus_list.append(taus)\n",
    "    print(\"Completed: {}/{}\".format(e,len(graphs[:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only T-1 embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_edge_sample = 400\n",
    "edge_operator = 'Average' #'Average', 'Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  4886\n",
      "TN:  5959\n",
      "FP:  1067\n",
      "FN:  2140\n",
      "F1: 0.7529085445720011\n",
      "[[5959 1067]\n",
      " [2140 4886]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79      7026\n",
      "           1       0.82      0.70      0.75      7026\n",
      "\n",
      "    accuracy                           0.77     14052\n",
      "   macro avg       0.78      0.77      0.77     14052\n",
      "weighted avg       0.78      0.77      0.77     14052\n",
      "\n",
      "Mean Average Precision: 0.7230638005107759\n",
      "Area Under ROC Curve: 0.7717762596071734\n",
      "Precision:  0.8207626406853687\n",
      "Recall:  0.695417022487902\n"
     ]
    }
   ],
   "source": [
    "#for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "for edge_operator in ['Concat']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_embedding = np.sum(np.asarray(chi_list[0:-1]),axis=0)\n",
    "cur_embedding = np.sum(np.asarray(chi_list),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  5250\n",
      "TN:  5471\n",
      "FP:  1555\n",
      "FN:  1776\n",
      "F1: 0.7591641963704722\n",
      "[[5471 1555]\n",
      " [1776 5250]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77      7026\n",
      "           1       0.77      0.75      0.76      7026\n",
      "\n",
      "    accuracy                           0.76     14052\n",
      "   macro avg       0.76      0.76      0.76     14052\n",
      "weighted avg       0.76      0.76      0.76     14052\n",
      "\n",
      "Mean Average Precision: 0.7028651635690089\n",
      "Area Under ROC Curve: 0.7629518929689724\n",
      "Precision:  0.7714915503306392\n",
      "Recall:  0.7472245943637916\n"
     ]
    }
   ],
   "source": [
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "#for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "for edge_operator in ['Concat']: \n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expotential Sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ BEGIN: 1 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  5219\n",
      "TN:  5726\n",
      "FP:  1300\n",
      "FN:  1807\n",
      "F1: 0.7706164636397195\n",
      "[[5726 1300]\n",
      " [1807 5219]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79      7026\n",
      "           1       0.80      0.74      0.77      7026\n",
      "\n",
      "    accuracy                           0.78     14052\n",
      "   macro avg       0.78      0.78      0.78     14052\n",
      "weighted avg       0.78      0.78      0.78     14052\n",
      "\n",
      "Mean Average Precision: 0.7232767172023428\n",
      "Area Under ROC Curve: 0.7788926843153999\n",
      "Precision:  0.8005829114894922\n",
      "Recall:  0.7428124110446912\n",
      "------------ END: 1 ---------------\n",
      "------------ BEGIN: 0.9 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  5136\n",
      "TN:  5780\n",
      "FP:  1246\n",
      "FN:  1890\n",
      "F1: 0.7661097852028639\n",
      "[[5780 1246]\n",
      " [1890 5136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      7026\n",
      "           1       0.80      0.73      0.77      7026\n",
      "\n",
      "    accuracy                           0.78     14052\n",
      "   macro avg       0.78      0.78      0.78     14052\n",
      "weighted avg       0.78      0.78      0.78     14052\n",
      "\n",
      "Mean Average Precision: 0.7227817829875388\n",
      "Area Under ROC Curve: 0.7768289211500142\n",
      "Precision:  0.804763397054215\n",
      "Recall:  0.730999146029035\n",
      "------------ END: 0.9 ---------------\n",
      "------------ BEGIN: 0.5 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  5327\n",
      "TN:  5543\n",
      "FP:  1483\n",
      "FN:  1699\n",
      "F1: 0.7700202370627349\n",
      "[[5543 1483]\n",
      " [1699 5327]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78      7026\n",
      "           1       0.78      0.76      0.77      7026\n",
      "\n",
      "    accuracy                           0.77     14052\n",
      "   macro avg       0.77      0.77      0.77     14052\n",
      "weighted avg       0.77      0.77      0.77     14052\n",
      "\n",
      "Mean Average Precision: 0.7139837641017024\n",
      "Area Under ROC Curve: 0.77355536578423\n",
      "Precision:  0.7822320117474303\n",
      "Recall:  0.7581838884144606\n",
      "------------ END: 0.5 ---------------\n",
      "------------ BEGIN: 0.3 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  5212\n",
      "TN:  5675\n",
      "FP:  1351\n",
      "FN:  1814\n",
      "F1: 0.7670910295091619\n",
      "[[5675 1351]\n",
      " [1814 5212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.78      7026\n",
      "           1       0.79      0.74      0.77      7026\n",
      "\n",
      "    accuracy                           0.77     14052\n",
      "   macro avg       0.78      0.77      0.77     14052\n",
      "weighted avg       0.78      0.77      0.77     14052\n",
      "\n",
      "Mean Average Precision: 0.7182044801791687\n",
      "Area Under ROC Curve: 0.7747651579846286\n",
      "Precision:  0.7941490172177358\n",
      "Recall:  0.7418161115855394\n",
      "------------ END: 0.3 ---------------\n"
     ]
    }
   ],
   "source": [
    "embeddings = chi_list\n",
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "for decay in [1,0.9,0.5,0.3]:\n",
    "    print(\"------------ BEGIN: {} ---------------\".format(decay))\n",
    "    exps = [math.pow(math.e , (-i * decay)) for i in range(1,len(embeddings[:-2]))]\n",
    "    exps.reverse()\n",
    "    temp_embedding = np.zeros((embeddings[0]).shape) \n",
    "    for c,e in zip(embeddings[0:-2],exps):\n",
    "         temp_embedding += e * c \n",
    "    prev_embedding = temp_embedding + embeddings[-2]\n",
    "    \n",
    "    # this is done so the last embedding has weight one. \n",
    "    cur_embedding = temp_embedding + exps[-1] * embeddings[-2] + embeddings[-1]\n",
    "    \n",
    "    for edge_operator in ['Concat']:\n",
    "        #for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "        try:\n",
    "            train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "            test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "            LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "            print(\"Edge Operator: {}\".format(edge_operator))\n",
    "            predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "            precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "            print('Precision: ', precision)\n",
    "            print('Recall: ', recall)\n",
    "        except:\n",
    "            print(\"Edge Operator: {} ERROR\".format(edge_operator))\n",
    "    print(\"------------ END: {} ---------------\".format(decay))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email Weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the graphs \n",
    "with open('/z/pujat/576/data/email_eu/email_1_week_dir.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 0/73\n",
      "Completed: 1/73\n",
      "Completed: 2/73\n",
      "Completed: 3/73\n",
      "Completed: 4/73\n",
      "Completed: 5/73\n",
      "Completed: 6/73\n",
      "Completed: 7/73\n",
      "Completed: 8/73\n",
      "Completed: 9/73\n",
      "Completed: 10/73\n",
      "Completed: 11/73\n",
      "Completed: 12/73\n",
      "Completed: 13/73\n",
      "Completed: 14/73\n",
      "Completed: 15/73\n",
      "Completed: 16/73\n",
      "Completed: 17/73\n",
      "Completed: 18/73\n",
      "Completed: 19/73\n",
      "Completed: 20/73\n",
      "Completed: 21/73\n",
      "Completed: 22/73\n",
      "Completed: 23/73\n",
      "Completed: 24/73\n",
      "Completed: 25/73\n",
      "Completed: 26/73\n",
      "Completed: 27/73\n",
      "Completed: 28/73\n",
      "Completed: 29/73\n",
      "Completed: 30/73\n",
      "Completed: 31/73\n",
      "Completed: 32/73\n",
      "Completed: 33/73\n",
      "Completed: 34/73\n",
      "Completed: 35/73\n",
      "Completed: 36/73\n",
      "Completed: 37/73\n",
      "Completed: 38/73\n",
      "Completed: 39/73\n",
      "Completed: 40/73\n",
      "Completed: 41/73\n",
      "Completed: 42/73\n",
      "Completed: 43/73\n",
      "Completed: 44/73\n",
      "Completed: 45/73\n",
      "Completed: 46/73\n",
      "Completed: 47/73\n",
      "Completed: 48/73\n",
      "Completed: 49/73\n",
      "Completed: 50/73\n",
      "Completed: 51/73\n",
      "Completed: 52/73\n",
      "Completed: 53/73\n",
      "Completed: 54/73\n",
      "Completed: 55/73\n",
      "Completed: 56/73\n",
      "Completed: 57/73\n",
      "Completed: 58/73\n",
      "Completed: 59/73\n",
      "Completed: 60/73\n",
      "Completed: 61/73\n",
      "Completed: 62/73\n",
      "Completed: 63/73\n",
      "Completed: 64/73\n",
      "Completed: 65/73\n",
      "Completed: 66/73\n",
      "Completed: 67/73\n",
      "Completed: 68/73\n",
      "Completed: 69/73\n",
      "Completed: 70/73\n",
      "Completed: 71/73\n",
      "Completed: 72/73\n"
     ]
    }
   ],
   "source": [
    "chi_list = []\n",
    "heat_print_list = []\n",
    "taus_list = []\n",
    "for e, g in enumerate(graphs[:-1]): #last embedding used for link prediction\n",
    "    chi, heat_print, taus = graphwave_alg(g, np.linspace(0,200,32), taus='auto', verbose=True)\n",
    "    chi_list.append(chi)\n",
    "    heat_print_list.append(heat_print)\n",
    "    taus_list.append(taus)\n",
    "    print(\"Completed: {}/{}\".format(e,len(graphs[:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only T-1 Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  2078\n",
      "TN:  2095\n",
      "FP:  590\n",
      "FN:  607\n",
      "F1: 0.7763870726695311\n",
      "[[2095  590]\n",
      " [ 607 2078]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      2685\n",
      "           1       0.78      0.77      0.78      2685\n",
      "\n",
      "    accuracy                           0.78      5370\n",
      "   macro avg       0.78      0.78      0.78      5370\n",
      "weighted avg       0.78      0.78      0.78      5370\n",
      "\n",
      "Mean Average Precision: 0.7158183478093355\n",
      "Area Under ROC Curve: 0.777094972067039\n",
      "Precision:  0.7788605697151424\n",
      "Recall:  0.7739292364990689\n"
     ]
    }
   ],
   "source": [
    "#for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "for edge_operator in ['Concat']:\n",
    "    try:\n",
    "        train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "        test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)\n",
    "\n",
    "        LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "        print(\"Edge Operator: {}\".format(edge_operator))\n",
    "        predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "        precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "        print('Precision: ', precision)\n",
    "        print('Recall: ', recall)\n",
    "    except:\n",
    "        print(\"Edge Operator: {} ERROR\".format(edge_operator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_embedding = np.sum(np.asarray(chi_list[0:-1]),axis=0)\n",
    "cur_embedding = np.sum(np.asarray(chi_list),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  2056\n",
      "TN:  2156\n",
      "FP:  529\n",
      "FN:  629\n",
      "F1: 0.7802656546489564\n",
      "[[2156  529]\n",
      " [ 629 2056]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.79      2685\n",
      "           1       0.80      0.77      0.78      2685\n",
      "\n",
      "    accuracy                           0.78      5370\n",
      "   macro avg       0.78      0.78      0.78      5370\n",
      "weighted avg       0.78      0.78      0.78      5370\n",
      "\n",
      "Mean Average Precision: 0.7261659985088014\n",
      "Area Under ROC Curve: 0.7843575418994414\n",
      "Precision:  0.795357833655706\n",
      "Recall:  0.7657355679702048\n"
     ]
    }
   ],
   "source": [
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "#for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "for edge_operator in ['Concat']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ BEGIN: 1 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  2025\n",
      "TN:  2153\n",
      "FP:  532\n",
      "FN:  660\n",
      "F1: 0.7726058756199924\n",
      "[[2153  532]\n",
      " [ 660 2025]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78      2685\n",
      "           1       0.79      0.75      0.77      2685\n",
      "\n",
      "    accuracy                           0.78      5370\n",
      "   macro avg       0.78      0.78      0.78      5370\n",
      "weighted avg       0.78      0.78      0.78      5370\n",
      "\n",
      "Mean Average Precision: 0.7201809907297964\n",
      "Area Under ROC Curve: 0.7780260707635009\n",
      "Precision:  0.791943684004693\n",
      "Recall:  0.7541899441340782\n",
      "------------ END: 1 ---------------\n",
      "------------ BEGIN: 0.9 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  2084\n",
      "TN:  2123\n",
      "FP:  562\n",
      "FN:  601\n",
      "F1: 0.781842055899456\n",
      "[[2123  562]\n",
      " [ 601 2084]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78      2685\n",
      "           1       0.79      0.78      0.78      2685\n",
      "\n",
      "    accuracy                           0.78      5370\n",
      "   macro avg       0.78      0.78      0.78      5370\n",
      "weighted avg       0.78      0.78      0.78      5370\n",
      "\n",
      "Mean Average Precision: 0.7232277806632688\n",
      "Area Under ROC Curve: 0.7834264432029795\n",
      "Precision:  0.7876039304610734\n",
      "Recall:  0.7761638733705772\n",
      "------------ END: 0.9 ---------------\n",
      "------------ BEGIN: 0.5 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  2030\n",
      "TN:  2180\n",
      "FP:  505\n",
      "FN:  655\n",
      "F1: 0.7777777777777778\n",
      "[[2180  505]\n",
      " [ 655 2030]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79      2685\n",
      "           1       0.80      0.76      0.78      2685\n",
      "\n",
      "    accuracy                           0.78      5370\n",
      "   macro avg       0.78      0.78      0.78      5370\n",
      "weighted avg       0.78      0.78      0.78      5370\n",
      "\n",
      "Mean Average Precision: 0.7274121332995419\n",
      "Area Under ROC Curve: 0.7839851024208566\n",
      "Precision:  0.8007889546351085\n",
      "Recall:  0.7560521415270018\n",
      "------------ END: 0.5 ---------------\n",
      "------------ BEGIN: 0.3 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  2100\n",
      "TN:  2089\n",
      "FP:  596\n",
      "FN:  585\n",
      "F1: 0.7805240661587066\n",
      "[[2089  596]\n",
      " [ 585 2100]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      2685\n",
      "           1       0.78      0.78      0.78      2685\n",
      "\n",
      "    accuracy                           0.78      5370\n",
      "   macro avg       0.78      0.78      0.78      5370\n",
      "weighted avg       0.78      0.78      0.78      5370\n",
      "\n",
      "Mean Average Precision: 0.7181589111947351\n",
      "Area Under ROC Curve: 0.7800744878957169\n",
      "Precision:  0.7789317507418397\n",
      "Recall:  0.7821229050279329\n",
      "------------ END: 0.3 ---------------\n"
     ]
    }
   ],
   "source": [
    "embeddings = chi_list\n",
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "for decay in [1,0.9,0.5,0.3]:\n",
    "    print(\"------------ BEGIN: {} ---------------\".format(decay))\n",
    "    exps = [math.pow(math.e , (-i * decay)) for i in range(1,len(embeddings[:-2]))]\n",
    "    exps.reverse()\n",
    "    temp_embedding = np.zeros((embeddings[0]).shape) \n",
    "    for c,e in zip(embeddings[0:-2],exps):\n",
    "         temp_embedding += e * c \n",
    "    prev_embedding = temp_embedding + embeddings[-2]\n",
    "    \n",
    "    # this is done so the last embedding has weight one. \n",
    "    cur_embedding = temp_embedding + exps[-1] * embeddings[-2] + embeddings[-1]\n",
    "    \n",
    "    #for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "    for edge_operator in ['Concat']:\n",
    "        try:\n",
    "            train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "            test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "            LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "            print(\"Edge Operator: {}\".format(edge_operator))\n",
    "            predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "            precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "            print('Precision: ', precision)\n",
    "            print('Recall: ', recall)\n",
    "        except:\n",
    "            print(\"Edge Operator: {} ERROR\".format(edge_operator))\n",
    "    print(\"------------ END: {} ---------------\".format(decay))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email Equal (weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the graphs \n",
    "with open('/z/pujat/576/data/email_eu/email_equal_weekly_dir.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 0/73\n",
      "Completed: 1/73\n",
      "Completed: 2/73\n",
      "Completed: 3/73\n",
      "Completed: 4/73\n",
      "Completed: 5/73\n",
      "Completed: 6/73\n",
      "Completed: 7/73\n",
      "Completed: 8/73\n",
      "Completed: 9/73\n",
      "Completed: 10/73\n",
      "Completed: 11/73\n",
      "Completed: 12/73\n",
      "Completed: 13/73\n",
      "Completed: 14/73\n",
      "Completed: 15/73\n",
      "Completed: 16/73\n",
      "Completed: 17/73\n",
      "Completed: 18/73\n",
      "Completed: 19/73\n",
      "Completed: 20/73\n",
      "Completed: 21/73\n",
      "Completed: 22/73\n",
      "Completed: 23/73\n",
      "Completed: 24/73\n",
      "Completed: 25/73\n",
      "Completed: 26/73\n",
      "Completed: 27/73\n",
      "Completed: 28/73\n",
      "Completed: 29/73\n",
      "Completed: 30/73\n",
      "Completed: 31/73\n",
      "Completed: 32/73\n",
      "Completed: 33/73\n",
      "Completed: 34/73\n",
      "Completed: 35/73\n",
      "Completed: 36/73\n",
      "Completed: 37/73\n",
      "Completed: 38/73\n",
      "Completed: 39/73\n",
      "Completed: 40/73\n",
      "Completed: 41/73\n",
      "Completed: 42/73\n",
      "Completed: 43/73\n",
      "Completed: 44/73\n",
      "Completed: 45/73\n",
      "Completed: 46/73\n",
      "Completed: 47/73\n",
      "Completed: 48/73\n",
      "Completed: 49/73\n",
      "Completed: 50/73\n",
      "Completed: 51/73\n",
      "Completed: 52/73\n",
      "Completed: 53/73\n",
      "Completed: 54/73\n",
      "Completed: 55/73\n",
      "Completed: 56/73\n",
      "Completed: 57/73\n",
      "Completed: 58/73\n",
      "Completed: 59/73\n",
      "Completed: 60/73\n",
      "Completed: 61/73\n",
      "Completed: 62/73\n",
      "Completed: 63/73\n",
      "Completed: 64/73\n",
      "Completed: 65/73\n",
      "Completed: 66/73\n",
      "Completed: 67/73\n",
      "Completed: 68/73\n",
      "Completed: 69/73\n",
      "Completed: 70/73\n",
      "Completed: 71/73\n",
      "Completed: 72/73\n"
     ]
    }
   ],
   "source": [
    "chi_list = []\n",
    "heat_print_list = []\n",
    "taus_list = []\n",
    "for e, g in enumerate(graphs[:-1]): #last embedding used for link prediction\n",
    "    chi, heat_print, taus = graphwave_alg(g, np.linspace(0,200,50), taus='auto', verbose=True)\n",
    "    chi_list.append(chi)\n",
    "    heat_print_list.append(heat_print)\n",
    "    taus_list.append(taus)\n",
    "    print(\"Completed: {}/{}\".format(e,len(graphs[:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only T-1 Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_edge_sample = 400\n",
    "edge_operator = 'Average' #'Average', 'Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  1678\n",
      "TN:  1563\n",
      "FP:  582\n",
      "FN:  467\n",
      "F1: 0.761861520998865\n",
      "[[1563  582]\n",
      " [ 467 1678]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75      2145\n",
      "           1       0.74      0.78      0.76      2145\n",
      "\n",
      "    accuracy                           0.76      4290\n",
      "   macro avg       0.76      0.76      0.76      4290\n",
      "weighted avg       0.76      0.76      0.76      4290\n",
      "\n",
      "Mean Average Precision: 0.6896866555273635\n",
      "Area Under ROC Curve: 0.7554778554778554\n",
      "Precision:  0.7424778761061946\n",
      "Recall:  0.7822843822843822\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in ['Concat']:\n",
    "    #for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_embedding = np.sum(np.asarray(chi_list[0:-1]),axis=0)\n",
    "cur_embedding = np.sum(np.asarray(chi_list),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  1686\n",
      "TN:  1664\n",
      "FP:  481\n",
      "FN:  459\n",
      "F1: 0.7820037105751392\n",
      "[[1664  481]\n",
      " [ 459 1686]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      2145\n",
      "           1       0.78      0.79      0.78      2145\n",
      "\n",
      "    accuracy                           0.78      4290\n",
      "   macro avg       0.78      0.78      0.78      4290\n",
      "weighted avg       0.78      0.78      0.78      4290\n",
      "\n",
      "Mean Average Precision: 0.7185387293832148\n",
      "Area Under ROC Curve: 0.780885780885781\n",
      "Precision:  0.7780341485925242\n",
      "Recall:  0.786013986013986\n"
     ]
    }
   ],
   "source": [
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "#for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "for edge_operator in ['Concat']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ BEGIN: 1 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  1647\n",
      "TN:  1683\n",
      "FP:  462\n",
      "FN:  498\n",
      "F1: 0.7743300423131171\n",
      "[[1683  462]\n",
      " [ 498 1647]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.78      2145\n",
      "           1       0.78      0.77      0.77      2145\n",
      "\n",
      "    accuracy                           0.78      4290\n",
      "   macro avg       0.78      0.78      0.78      4290\n",
      "weighted avg       0.78      0.78      0.78      4290\n",
      "\n",
      "Mean Average Precision: 0.7157138736086104\n",
      "Area Under ROC Curve: 0.7762237762237763\n",
      "Precision:  0.7809388335704125\n",
      "Recall:  0.7678321678321678\n",
      "------------ END: 1 ---------------\n",
      "------------ BEGIN: 0.9 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  1680\n",
      "TN:  1652\n",
      "FP:  493\n",
      "FN:  465\n",
      "F1: 0.778138026864289\n",
      "[[1652  493]\n",
      " [ 465 1680]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.78      2145\n",
      "           1       0.77      0.78      0.78      2145\n",
      "\n",
      "    accuracy                           0.78      4290\n",
      "   macro avg       0.78      0.78      0.78      4290\n",
      "weighted avg       0.78      0.78      0.78      4290\n",
      "\n",
      "Mean Average Precision: 0.7139158586466456\n",
      "Area Under ROC Curve: 0.7766899766899766\n",
      "Precision:  0.7731247123791992\n",
      "Recall:  0.7832167832167832\n",
      "------------ END: 0.9 ---------------\n",
      "------------ BEGIN: 0.5 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  1661\n",
      "TN:  1677\n",
      "FP:  468\n",
      "FN:  484\n",
      "F1: 0.7772578380907814\n",
      "[[1677  468]\n",
      " [ 484 1661]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      2145\n",
      "           1       0.78      0.77      0.78      2145\n",
      "\n",
      "    accuracy                           0.78      4290\n",
      "   macro avg       0.78      0.78      0.78      4290\n",
      "weighted avg       0.78      0.78      0.78      4290\n",
      "\n",
      "Mean Average Precision: 0.7169587262588673\n",
      "Area Under ROC Curve: 0.778088578088578\n",
      "Precision:  0.7801784875528417\n",
      "Recall:  0.7743589743589744\n",
      "------------ END: 0.5 ---------------\n",
      "------------ BEGIN: 0.3 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  1658\n",
      "TN:  1711\n",
      "FP:  434\n",
      "FN:  487\n",
      "F1: 0.7826292187868775\n",
      "[[1711  434]\n",
      " [ 487 1658]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      2145\n",
      "           1       0.79      0.77      0.78      2145\n",
      "\n",
      "    accuracy                           0.79      4290\n",
      "   macro avg       0.79      0.79      0.79      4290\n",
      "weighted avg       0.79      0.79      0.79      4290\n",
      "\n",
      "Mean Average Precision: 0.7261241626442392\n",
      "Area Under ROC Curve: 0.7853146853146854\n",
      "Precision:  0.7925430210325047\n",
      "Recall:  0.772960372960373\n",
      "------------ END: 0.3 ---------------\n"
     ]
    }
   ],
   "source": [
    "embeddings = chi_list\n",
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "for decay in [1,0.9,0.5,0.3]:\n",
    "    print(\"------------ BEGIN: {} ---------------\".format(decay))\n",
    "    exps = [math.pow(math.e , (-i * decay)) for i in range(1,len(embeddings[:-2]))]\n",
    "    exps.reverse()\n",
    "    temp_embedding = np.zeros((embeddings[0]).shape) \n",
    "    for c,e in zip(embeddings[0:-2],exps):\n",
    "         temp_embedding += e * c \n",
    "    prev_embedding = temp_embedding + embeddings[-2]\n",
    "    \n",
    "    # this is done so the last embedding has weight one. \n",
    "    cur_embedding = temp_embedding + exps[-1] * embeddings[-2] + embeddings[-1]\n",
    "    \n",
    "    #for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "    for edge_operator in ['Concat']:\n",
    "        try:\n",
    "            train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "            test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "            LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "            print(\"Edge Operator: {}\".format(edge_operator))\n",
    "            predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "            precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "            print('Precision: ', precision)\n",
    "            print('Recall: ', recall)\n",
    "        except:\n",
    "            print(\"Edge Operator: {} ERROR\".format(edge_operator))\n",
    "    print(\"------------ END: {} ---------------\".format(decay))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email Equal(Monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the graphs \n",
    "with open('/z/pujat/576/data/email_eu/email_equal_monthly_dir.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 0/16\n",
      "Completed: 1/16\n",
      "Completed: 2/16\n",
      "Completed: 3/16\n",
      "Completed: 4/16\n",
      "Completed: 5/16\n",
      "Completed: 6/16\n",
      "Completed: 7/16\n",
      "Completed: 8/16\n",
      "Completed: 9/16\n",
      "Completed: 10/16\n",
      "Completed: 11/16\n",
      "Completed: 12/16\n",
      "Completed: 13/16\n",
      "Completed: 14/16\n",
      "Completed: 15/16\n"
     ]
    }
   ],
   "source": [
    "chi_list = []\n",
    "heat_print_list = []\n",
    "taus_list = []\n",
    "for e, g in enumerate(graphs[:-1]): #last embedding used for link prediction\n",
    "    chi, heat_print, taus = graphwave_alg(g, np.linspace(0,200,50), taus='auto', verbose=True)\n",
    "    chi_list.append(chi)\n",
    "    heat_print_list.append(heat_print)\n",
    "    taus_list.append(taus)\n",
    "    print(\"Completed: {}/{}\".format(e,len(graphs[:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only T-1 Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_edge_sample = 400\n",
    "edge_operator = 'Average' #'Average', 'Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  4421\n",
      "TN:  3790\n",
      "FP:  1539\n",
      "FN:  908\n",
      "F1: 0.7832403224377713\n",
      "[[3790 1539]\n",
      " [ 908 4421]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76      5329\n",
      "           1       0.74      0.83      0.78      5329\n",
      "\n",
      "    accuracy                           0.77     10658\n",
      "   macro avg       0.77      0.77      0.77     10658\n",
      "weighted avg       0.77      0.77      0.77     10658\n",
      "\n",
      "Mean Average Precision: 0.7005822578999801\n",
      "Area Under ROC Curve: 0.7704072058547571\n",
      "Precision:  0.7417785234899329\n",
      "Recall:  0.829611559392006\n"
     ]
    }
   ],
   "source": [
    "#for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "for edge_operator in ['Concat']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, chi_list[-2], edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, chi_list[-1], edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_embedding = np.sum(np.asarray(chi_list[0:-1]),axis=0)\n",
    "cur_embedding = np.sum(np.asarray(chi_list),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  4029\n",
      "TN:  4142\n",
      "FP:  1187\n",
      "FN:  1300\n",
      "F1: 0.7641536273115221\n",
      "[[4142 1187]\n",
      " [1300 4029]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      5329\n",
      "           1       0.77      0.76      0.76      5329\n",
      "\n",
      "    accuracy                           0.77     10658\n",
      "   macro avg       0.77      0.77      0.77     10658\n",
      "weighted avg       0.77      0.77      0.77     10658\n",
      "\n",
      "Mean Average Precision: 0.7059719318533733\n",
      "Area Under ROC Curve: 0.766654156502158\n",
      "Precision:  0.772430981595092\n",
      "Recall:  0.7560517920810659\n"
     ]
    }
   ],
   "source": [
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "#for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "for edge_operator in ['Concat']:\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ BEGIN: 1 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  4286\n",
      "TN:  3932\n",
      "FP:  1397\n",
      "FN:  1043\n",
      "F1: 0.7784235379585907\n",
      "[[3932 1397]\n",
      " [1043 4286]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      5329\n",
      "           1       0.75      0.80      0.78      5329\n",
      "\n",
      "    accuracy                           0.77     10658\n",
      "   macro avg       0.77      0.77      0.77     10658\n",
      "weighted avg       0.77      0.77      0.77     10658\n",
      "\n",
      "Mean Average Precision: 0.7044308039698056\n",
      "Area Under ROC Curve: 0.7710639894914618\n",
      "Precision:  0.7541791307408059\n",
      "Recall:  0.8042784762619628\n",
      "------------ END: 1 ---------------\n",
      "------------ BEGIN: 0.9 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  4226\n",
      "TN:  4016\n",
      "FP:  1313\n",
      "FN:  1103\n",
      "F1: 0.777695988222304\n",
      "[[4016 1313]\n",
      " [1103 4226]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.77      5329\n",
      "           1       0.76      0.79      0.78      5329\n",
      "\n",
      "    accuracy                           0.77     10658\n",
      "   macro avg       0.77      0.77      0.77     10658\n",
      "weighted avg       0.77      0.77      0.77     10658\n",
      "\n",
      "Mean Average Precision: 0.7085272885953002\n",
      "Area Under ROC Curve: 0.7733158191030212\n",
      "Precision:  0.7629536017331648\n",
      "Recall:  0.7930193282041659\n",
      "------------ END: 0.9 ---------------\n",
      "------------ BEGIN: 0.5 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  4086\n",
      "TN:  4167\n",
      "FP:  1162\n",
      "FN:  1243\n",
      "F1: 0.7726198354921056\n",
      "[[4167 1162]\n",
      " [1243 4086]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.78      5329\n",
      "           1       0.78      0.77      0.77      5329\n",
      "\n",
      "    accuracy                           0.77     10658\n",
      "   macro avg       0.77      0.77      0.77     10658\n",
      "weighted avg       0.77      0.77      0.77     10658\n",
      "\n",
      "Mean Average Precision: 0.7136024296417669\n",
      "Area Under ROC Curve: 0.7743479076749858\n",
      "Precision:  0.7785823170731707\n",
      "Recall:  0.766747982735973\n",
      "------------ END: 0.5 ---------------\n",
      "------------ BEGIN: 0.3 ---------------\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  4076\n",
      "TN:  4172\n",
      "FP:  1157\n",
      "FN:  1253\n",
      "F1: 0.7718235182730544\n",
      "[[4172 1157]\n",
      " [1253 4076]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.78      5329\n",
      "           1       0.78      0.76      0.77      5329\n",
      "\n",
      "    accuracy                           0.77     10658\n",
      "   macro avg       0.77      0.77      0.77     10658\n",
      "weighted avg       0.77      0.77      0.77     10658\n",
      "\n",
      "Mean Average Precision: 0.7133250321112352\n",
      "Area Under ROC Curve: 0.7738787765059111\n",
      "Precision:  0.7789031148480795\n",
      "Recall:  0.7648714580596735\n",
      "------------ END: 0.3 ---------------\n"
     ]
    }
   ],
   "source": [
    "embeddings = chi_list\n",
    "num_edge_sample = 400\n",
    "#Average' or 'Hadamard' or 'Weighted-L1' or 'Weighted-L2'\n",
    "for decay in [1,0.9,0.5,0.3]:\n",
    "    print(\"------------ BEGIN: {} ---------------\".format(decay))\n",
    "    exps = [math.pow(math.e , (-i * decay)) for i in range(1,len(embeddings[:-2]))]\n",
    "    exps.reverse()\n",
    "    temp_embedding = np.zeros((embeddings[0]).shape) \n",
    "    for c,e in zip(embeddings[0:-2],exps):\n",
    "         temp_embedding += e * c \n",
    "    prev_embedding = temp_embedding + embeddings[-2]\n",
    "    \n",
    "    # this is done so the last embedding has weight one. \n",
    "    cur_embedding = temp_embedding + exps[-1] * embeddings[-2] + embeddings[-1]\n",
    "    \n",
    "    #for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2']:\n",
    "    for edge_operator in ['Concat']:\n",
    "        try:\n",
    "            train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, prev_embedding, edge_operator)\n",
    "            test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, cur_embedding, edge_operator)\n",
    "\n",
    "            LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "            print(\"Edge Operator: {}\".format(edge_operator))\n",
    "            predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "            precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "            print('Precision: ', precision)\n",
    "            print('Recall: ', recall)\n",
    "        except:\n",
    "            print(\"Edge Operator: {} ERROR\".format(edge_operator))\n",
    "    print(\"------------ END: {} ---------------\".format(decay))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
