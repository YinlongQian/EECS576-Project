{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import pickle\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_features(node_emb_1, node_emb_2, operator):\n",
    "    node_emb_1 = np.asfarray(node_emb_1,float)\n",
    "    node_emb_2 = np.asfarray(node_emb_2, float)\n",
    "    # combine two nodes' embeddings with specificed operator\n",
    "    if operator == 'Average':\n",
    "        edge = [((x + y) / 2.0) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Hadamard':\n",
    "        edge = [(x * y) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Weighted-L1':\n",
    "        edge = [abs(x - y) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Weighted-L2':\n",
    "        edge = [abs(x - y)**2 for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Concat':\n",
    "        edge = np.concatenate((node_emb_1, node_emb_2), axis=None) \n",
    "    else:\n",
    "        print(\"Generate edge features: Operator not supported\")\n",
    "        print(\"Use default operator: Weighted-L1\")\n",
    "        edge = [abs(x - y) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "        \n",
    "    return edge\n",
    "def generate_edge_features(edge_list, node_embeddings, operator):\n",
    "    edge_features_mtx = []\n",
    "    \n",
    "    # generate features for each edge in the list\n",
    "    for node_index_1, node_index_2 in edge_list:\n",
    "        node_emb_1 = node_embeddings[node_index_1-1]\n",
    "        node_emb_2 = node_embeddings[node_index_2-1]\n",
    "        \n",
    "        edge_features_mtx.append(edge_features(node_emb_1, node_emb_2, operator))\n",
    "        \n",
    "    return edge_features_mtx\n",
    "\n",
    "def generate_train_set(graph_train, num_edge_sample, node_embeddings, edge_operator,):\n",
    "    edge_list = list(graph_train.edges)\n",
    "    num_nodes = graph_train.number_of_nodes()\n",
    "    \n",
    "    train_edges = []\n",
    "    train_edges_labels = [1] * num_edge_sample + [0] * num_edge_sample\n",
    "    \n",
    "    random.seed(0)\n",
    "    \n",
    "    # sample edges with label 1 (true edges)\n",
    "    for edge_num in range(num_edge_sample):\n",
    "        rand_index = random.randint(0, len(edge_list) - 1)\n",
    "        \n",
    "        #train_edges.append(tuple(edge_list[rand_index]))\n",
    "        train_edges.append(edge_list[rand_index])\n",
    "    non_edge_num = 0\n",
    "    \n",
    "    # sample edges with label 0 (non-exist edges)\n",
    "    while(non_edge_num < num_edge_sample):\n",
    "        rand_nodes = tuple(np.random.randint(low=0,high=num_nodes, size=2))\n",
    "        \n",
    "        if rand_nodes not in edge_list:\n",
    "            train_edges.append(rand_nodes)\n",
    "            non_edge_num += 1\n",
    "\n",
    "    train_edges_features_mtx = generate_edge_features(train_edges, node_embeddings, edge_operator)\n",
    "            \n",
    "    return train_edges, train_edges_features_mtx, train_edges_labels\n",
    "\n",
    "def generate_test_set(graph_test, node_embeddings, edge_operator):\n",
    "    edge_list = graph_test.edges\n",
    "    nodes_with_edge = set()\n",
    "    \n",
    "    for edge in edge_list:\n",
    "        nodes_with_edge.add(edge[0])\n",
    "        nodes_with_edge.add(edge[1])\n",
    "    \n",
    "    num_nodes = graph_test.number_of_nodes()\n",
    "    \n",
    "    test_edges = []\n",
    "    test_edges_labels = []\n",
    "    \n",
    "    num_edge_sample = len(edge_list)\n",
    "    non_edge_num = 0 \n",
    "    # sample edges with label 0 (non-exist edges)\n",
    "    \n",
    "    while(non_edge_num < num_edge_sample):\n",
    "        rand_nodes = tuple(np.random.randint(low=0,high=num_nodes, size=2))\n",
    "        \n",
    "        if rand_nodes not in edge_list:\n",
    "            test_edges.append(rand_nodes)\n",
    "            test_edges_labels.append(0)\n",
    "            non_edge_num += 1\n",
    "        \n",
    "    for edge in edge_list:\n",
    "        test_edges.append(edge)\n",
    "        test_edges_labels.append(1)\n",
    "    \n",
    "    test_edges_features_mtx = generate_edge_features(test_edges, node_embeddings, edge_operator)\n",
    "    \n",
    "    return test_edges, test_edges_features_mtx, test_edges_labels\n",
    "\n",
    "def build_clf(feature_mtx, response_vec):\n",
    "   \n",
    "    logistic_regression_model = LogisticRegression(random_state = 0,max_iter=5000,solver='liblinear',verbose=1,tol=1e-6)\n",
    "    binary_clf = logistic_regression_model.fit(feature_mtx, response_vec)\n",
    "    \n",
    "    return binary_clf\n",
    "\n",
    "def pred_links(feature_mtx, LR_clf):\n",
    "    predict_edges_labels = LR_clf.predict(feature_mtx)\n",
    "    \n",
    "    return predict_edges_labels\n",
    "\n",
    "def precision_recall(predict_labels, true_labels):\n",
    "    true_positive  = false_positive = 0\n",
    "    true_negative =  false_negative = 0\n",
    "    \n",
    "    for p_label, true_label in zip(predict_labels, true_labels):\n",
    "        \n",
    "        #print(p_label,true_label)\n",
    "        if p_label == true_label and true_label == 1:\n",
    "            true_positive += 1\n",
    "        elif p_label == true_label and true_label == 0:\n",
    "            true_negative += 1\n",
    "        elif p_label != true_label and true_label == 1:\n",
    "            false_negative += 1\n",
    "        elif p_label != true_label and true_label == 0:\n",
    "            false_positive += 1\n",
    "\n",
    "    print(\"TP: \", true_positive)\n",
    "    print(\"TN: \", true_negative)\n",
    "    print(\"FP: \", false_positive)\n",
    "    print(\"FN: \", false_negative)\n",
    "    \n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "    if (precision + recall) != 0.0:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        print(\"F1: {}\".format(f1))\n",
    "    else:\n",
    "        print(\"F1: Divide-by-zero\")\n",
    "    \n",
    "    cm = metrics.confusion_matrix(true_labels, predict_labels)\n",
    "    print(cm)\n",
    "    print(metrics.classification_report(true_labels, predict_labels))\n",
    "    map = metrics.average_precision_score(true_labels, predict_labels)\n",
    "    print('Mean Average Precision: {}'.format(map))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(true_labels, predict_labels)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print('Area Under ROC Curve: {}'.format(roc_auc))\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon-Food - Monthly\n",
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and testing graph\n",
    "with open('../graphs/amazon_food/amazon_food_monthly_dir.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "    \n",
    "graphs = graphs[-20:]\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]\n",
    "\n",
    "# parameters\n",
    "num_edge_sample = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_snapshots = len(graphs)\n",
    "num_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_list = []\n",
    "for i in range(num_snapshots):\n",
    "    file = '../embeddings/amazon_food/em-amazon-month-' + str(i + 100) + '.npy'\n",
    "    node_embedding = np.load(file)\n",
    "    emb_list.append(node_embedding)\n",
    "print(len(emb_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### independent / no combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings_training = emb_list[-3]\n",
    "node_embeddings_testing = emb_list[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(emb_list)):\n",
    "    emb_list[i] = np.asfarray(emb_list[i],float)\n",
    "node_embeddings_training = np.sum(np.asarray(emb_list[0:-2]),axis=0)\n",
    "node_embeddings_testing = np.sum(np.asarray(emb_list[0:-1]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge_operator in ['Average', 'Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expdecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [np.exp(-i * 0.3) for i in range(1,21)]\n",
    "node_embeddings_training = np.zeros((emb_list[0]).shape) \n",
    "for c,e in zip(emb_list[0:-2],exps[:-1]):\n",
    "    node_embeddings_training += e * c\n",
    "print(len(emb_list))\n",
    "print(len(exps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings_testing = np.zeros((emb_list[0]).shape) \n",
    "for c,e in zip(emb_list[0:-1],exps[:-1]):\n",
    "    node_embeddings_testing += e * c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge_operator in [ 'Average', 'Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon-Food - Weekly\n",
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and testing graph\n",
    "with open('../graphs/amazon_food/amazon_food_weekly_dir.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "    \n",
    "graphs = graphs[-20:]\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]\n",
    "\n",
    "# parameters\n",
    "num_edge_sample = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_snapshots = len(graphs)\n",
    "num_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_list = []\n",
    "for i in range(num_snapshots):\n",
    "    file = '../embeddings/amazon_food/em-amazon-week-' + str(i + 216) + '.npy'\n",
    "    node_embedding = np.load(file)\n",
    "    emb_list.append(node_embedding)\n",
    "print(len(emb_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### independent / no combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings_training = emb_list[-3]\n",
    "node_embeddings_testing = emb_list[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge_operator in ['Average', 'Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(emb_list)):\n",
    "    emb_list[i] = np.asfarray(emb_list[i],float)\n",
    "node_embeddings_training = np.sum(np.asarray(emb_list[0:-2]),axis=0)\n",
    "node_embeddings_testing = np.sum(np.asarray(emb_list[0:-1]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge_operator in ['Average', 'Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expdecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [np.exp(-i * 0.3) for i in range(1,21)]\n",
    "node_embeddings_training = np.zeros((emb_list[0]).shape) \n",
    "for c,e in zip(emb_list[0:-2],exps[:-1]):\n",
    "    node_embeddings_training += e * c \n",
    "node_embeddings_testing = np.zeros((emb_list[0]).shape) \n",
    "for c,e in zip(emb_list[0:-1],exps[:-1]):\n",
    "    node_embeddings_testing += e * c\n",
    "print(len(emb_list))\n",
    "print(len(exps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge_operator in ['Average', 'Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon-Food - Equal Monthly\n",
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and testing graph\n",
    "with open('../graphs/amazon_food/amazon_food_equal_monthly_dir.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "graphs = graphs[-20:]\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]\n",
    "\n",
    "# parameters\n",
    "num_edge_sample = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_snapshots = len(graphs)\n",
    "num_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_list = []\n",
    "for i in range(num_snapshots):\n",
    "    file = '../embeddings/amazon_food/em-amazon-equal-month-' + str(i + 100) + '.npy'\n",
    "    node_embedding = np.load(file)\n",
    "    emb_list.append(node_embedding)\n",
    "print(len(emb_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### independent / no combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings_training = emb_list[-3]\n",
    "node_embeddings_testing = emb_list[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(emb_list)):\n",
    "    emb_list[i] = np.asfarray(emb_list[i],float)\n",
    "node_embeddings_training = np.sum(np.asarray(emb_list[0:-2]),axis=0)\n",
    "node_embeddings_testing = np.sum(np.asarray(emb_list[0:-1]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge_operator in ['Average', 'Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expdecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [np.exp(-i * 0.9) for i in range(1,21)]\n",
    "node_embeddings_training = np.zeros((emb_list[0]).shape) \n",
    "for c,e in zip(emb_list[0:-2],exps[:-1]):\n",
    "    node_embeddings_training += e * c \n",
    "node_embeddings_testing = np.zeros((emb_list[0]).shape) \n",
    "for c,e in zip(emb_list[0:-1],exps[:-1]):\n",
    "    node_embeddings_testing += e * c\n",
    "print(len(exps))\n",
    "print(len(emb_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge_operator in ['Average', 'Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon-Food - Equal Weekly\n",
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and testing graph\n",
    "with open('../data/amazon_food/amazon_food_equal_weekly_dir.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "graphs = graphs[-20:]\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]\n",
    "\n",
    "# parameters\n",
    "num_edge_sample = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_snapshots = len(graphs)\n",
    "num_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "emb_list = []\n",
    "for i in range(num_snapshots):\n",
    "    file = '../data/amazon_food/embeddings/em-amazon-equal-week-' + str(i + 216) + '.npy'\n",
    "    node_embedding = np.load(file)\n",
    "    emb_list.append(node_embedding)\n",
    "print(len(emb_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings_training = emb_list[-3]\n",
    "node_embeddings_testing = emb_list[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  116\n",
      "TN:  213\n",
      "FP:  107\n",
      "FN:  204\n",
      "F1: 0.42725598526703495\n",
      "[[213 107]\n",
      " [204 116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.67      0.58       320\n",
      "           1       0.52      0.36      0.43       320\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       640\n",
      "   macro avg       0.52      0.51      0.50       640\n",
      "weighted avg       0.52      0.51      0.50       640\n",
      "\n",
      "Mean Average Precision: 0.5073150224215246\n",
      "Area Under ROC Curve: 0.5140625\n",
      "Precision:  0.5201793721973094\n",
      "Recall:  0.3625\n",
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  132\n",
      "TN:  185\n",
      "FP:  135\n",
      "FN:  188\n",
      "F1: 0.44974446337308344\n",
      "[[185 135]\n",
      " [188 132]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.58      0.53       320\n",
      "           1       0.49      0.41      0.45       320\n",
      "\n",
      "   micro avg       0.50      0.50      0.50       640\n",
      "   macro avg       0.50      0.50      0.49       640\n",
      "weighted avg       0.50      0.50      0.49       640\n",
      "\n",
      "Mean Average Precision: 0.49768258426966294\n",
      "Area Under ROC Curve: 0.49531250000000004\n",
      "Precision:  0.4943820224719101\n",
      "Recall:  0.4125\n",
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  133\n",
      "TN:  206\n",
      "FP:  114\n",
      "FN:  187\n",
      "F1: 0.46913580246913583\n",
      "[[206 114]\n",
      " [187 133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.64      0.58       320\n",
      "           1       0.54      0.42      0.47       320\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       640\n",
      "   macro avg       0.53      0.53      0.52       640\n",
      "weighted avg       0.53      0.53      0.52       640\n",
      "\n",
      "Mean Average Precision: 0.5159855769230769\n",
      "Area Under ROC Curve: 0.5296875\n",
      "Precision:  0.5384615384615384\n",
      "Recall:  0.415625\n",
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  135\n",
      "TN:  216\n",
      "FP:  104\n",
      "FN:  185\n",
      "F1: 0.48300536672629696\n",
      "[[216 104]\n",
      " [185 135]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.68      0.60       320\n",
      "           1       0.56      0.42      0.48       320\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       640\n",
      "   macro avg       0.55      0.55      0.54       640\n",
      "weighted avg       0.55      0.55      0.54       640\n",
      "\n",
      "Mean Average Precision: 0.5273600941422594\n",
      "Area Under ROC Curve: 0.5484375\n",
      "Precision:  0.5648535564853556\n",
      "Recall:  0.421875\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  96\n",
      "TN:  228\n",
      "FP:  92\n",
      "FN:  224\n",
      "F1: 0.3779527559055118\n",
      "[[228  92]\n",
      " [224  96]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.71      0.59       320\n",
      "           1       0.51      0.30      0.38       320\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       640\n",
      "   macro avg       0.51      0.51      0.48       640\n",
      "weighted avg       0.51      0.51      0.48       640\n",
      "\n",
      "Mean Average Precision: 0.5031914893617021\n",
      "Area Under ROC Curve: 0.50625\n",
      "Precision:  0.5106382978723404\n",
      "Recall:  0.3\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(emb_list)):\n",
    "    emb_list[i] = np.asfarray(emb_list[i],float)\n",
    "node_embeddings_training = np.sum(np.asarray(emb_list[0:-2]),axis=0)\n",
    "node_embeddings_testing = np.sum(np.asarray(emb_list[0:-1]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  120\n",
      "TN:  208\n",
      "FP:  112\n",
      "FN:  200\n",
      "F1: 0.4347826086956522\n",
      "[[208 112]\n",
      " [200 120]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.65      0.57       320\n",
      "           1       0.52      0.38      0.43       320\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       640\n",
      "   macro avg       0.51      0.51      0.50       640\n",
      "weighted avg       0.51      0.51      0.50       640\n",
      "\n",
      "Mean Average Precision: 0.5064655172413793\n",
      "Area Under ROC Curve: 0.5125\n",
      "Precision:  0.5172413793103449\n",
      "Recall:  0.375\n",
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  116\n",
      "TN:  202\n",
      "FP:  118\n",
      "FN:  204\n",
      "F1: 0.41877256317689526\n",
      "[[202 118]\n",
      " [204 116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.63      0.56       320\n",
      "           1       0.50      0.36      0.42       320\n",
      "\n",
      "   micro avg       0.50      0.50      0.50       640\n",
      "   macro avg       0.50      0.50      0.49       640\n",
      "weighted avg       0.50      0.50      0.49       640\n",
      "\n",
      "Mean Average Precision: 0.4984508547008547\n",
      "Area Under ROC Curve: 0.496875\n",
      "Precision:  0.49572649572649574\n",
      "Recall:  0.3625\n",
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  145\n",
      "TN:  202\n",
      "FP:  118\n",
      "FN:  175\n",
      "F1: 0.4974271012006862\n",
      "[[202 118]\n",
      " [175 145]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.63      0.58       320\n",
      "           1       0.55      0.45      0.50       320\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       640\n",
      "   macro avg       0.54      0.54      0.54       640\n",
      "weighted avg       0.54      0.54      0.54       640\n",
      "\n",
      "Mean Average Precision: 0.5232592680608366\n",
      "Area Under ROC Curve: 0.5421875\n",
      "Precision:  0.5513307984790875\n",
      "Recall:  0.453125\n",
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  153\n",
      "TN:  196\n",
      "FP:  124\n",
      "FN:  167\n",
      "F1: 0.5125628140703518\n",
      "[[196 124]\n",
      " [167 153]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.61      0.57       320\n",
      "           1       0.55      0.48      0.51       320\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       640\n",
      "   macro avg       0.55      0.55      0.54       640\n",
      "weighted avg       0.55      0.55      0.54       640\n",
      "\n",
      "Mean Average Precision: 0.5250282039711192\n",
      "Area Under ROC Curve: 0.5453125000000001\n",
      "Precision:  0.5523465703971119\n",
      "Recall:  0.478125\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  122\n",
      "TN:  226\n",
      "FP:  94\n",
      "FN:  198\n",
      "F1: 0.4552238805970149\n",
      "[[226  94]\n",
      " [198 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.71      0.61       320\n",
      "           1       0.56      0.38      0.46       320\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       640\n",
      "   macro avg       0.55      0.54      0.53       640\n",
      "weighted avg       0.55      0.54      0.53       640\n",
      "\n",
      "Mean Average Precision: 0.5247106481481482\n",
      "Area Under ROC Curve: 0.5437500000000001\n",
      "Precision:  0.5648148148148148\n",
      "Recall:  0.38125\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in ['Average', 'Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expdecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "exps = [np.exp(-i * 0.3) for i in range(1,21)]\n",
    "node_embeddings_training = np.zeros((emb_list[0]).shape) \n",
    "for c,e in zip(emb_list[0:-2],exps[:-1]):\n",
    "    node_embeddings_training += e * c \n",
    "node_embeddings_testing = np.zeros((emb_list[0]).shape) \n",
    "for c,e in zip(emb_list[0:-1],exps[:-1]):\n",
    "    node_embeddings_testing += e * c \n",
    "print(len(exps))\n",
    "print(len(emb_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  117\n",
      "TN:  218\n",
      "FP:  102\n",
      "FN:  203\n",
      "F1: 0.4341372912801484\n",
      "[[218 102]\n",
      " [203 117]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.68      0.59       320\n",
      "           1       0.53      0.37      0.43       320\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       640\n",
      "   macro avg       0.53      0.52      0.51       640\n",
      "weighted avg       0.53      0.52      0.51       640\n",
      "\n",
      "Mean Average Precision: 0.512521404109589\n",
      "Area Under ROC Curve: 0.5234375\n",
      "Precision:  0.5342465753424658\n",
      "Recall:  0.365625\n",
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  113\n",
      "TN:  195\n",
      "FP:  125\n",
      "FN:  207\n",
      "F1: 0.40501792114695345\n",
      "[[195 125]\n",
      " [207 113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.61      0.54       320\n",
      "           1       0.47      0.35      0.41       320\n",
      "\n",
      "   micro avg       0.48      0.48      0.48       640\n",
      "   macro avg       0.48      0.48      0.47       640\n",
      "weighted avg       0.48      0.48      0.47       640\n",
      "\n",
      "Mean Average Precision: 0.49109768907563023\n",
      "Area Under ROC Curve: 0.48124999999999996\n",
      "Precision:  0.47478991596638653\n",
      "Recall:  0.353125\n",
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  130\n",
      "TN:  211\n",
      "FP:  109\n",
      "FN:  190\n",
      "F1: 0.4651162790697674\n",
      "[[211 109]\n",
      " [190 130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.66      0.59       320\n",
      "           1       0.54      0.41      0.47       320\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       640\n",
      "   macro avg       0.54      0.53      0.53       640\n",
      "weighted avg       0.54      0.53      0.53       640\n",
      "\n",
      "Mean Average Precision: 0.5178478033472803\n",
      "Area Under ROC Curve: 0.5328125\n",
      "Precision:  0.5439330543933054\n",
      "Recall:  0.40625\n",
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  122\n",
      "TN:  223\n",
      "FP:  97\n",
      "FN:  198\n",
      "F1: 0.4526901669758812\n",
      "[[223  97]\n",
      " [198 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.70      0.60       320\n",
      "           1       0.56      0.38      0.45       320\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       640\n",
      "   macro avg       0.54      0.54      0.53       640\n",
      "weighted avg       0.54      0.54      0.53       640\n",
      "\n",
      "Mean Average Precision: 0.5217608447488584\n",
      "Area Under ROC Curve: 0.5390625\n",
      "Precision:  0.5570776255707762\n",
      "Recall:  0.38125\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  116\n",
      "TN:  230\n",
      "FP:  90\n",
      "FN:  204\n",
      "F1: 0.4410646387832699\n",
      "[[230  90]\n",
      " [204 116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.72      0.61       320\n",
      "           1       0.56      0.36      0.44       320\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       640\n",
      "   macro avg       0.55      0.54      0.53       640\n",
      "weighted avg       0.55      0.54      0.53       640\n",
      "\n",
      "Mean Average Precision: 0.5228762135922329\n",
      "Area Under ROC Curve: 0.540625\n",
      "Precision:  0.5631067961165048\n",
      "Recall:  0.3625\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in ['Average', 'Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
