{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import pickle\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_features(node_emb_1, node_emb_2, operator):\n",
    "    node_emb_1 = np.asfarray(node_emb_1,float)\n",
    "    node_emb_2 = np.asfarray(node_emb_2, float)\n",
    "    # combine two nodes' embeddings with specificed operator\n",
    "    if operator == 'Average':\n",
    "        edge = [((x + y) / 2.0) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Hadamard':\n",
    "        edge = [(x * y) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Weighted-L1':\n",
    "        edge = [abs(x - y) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Weighted-L2':\n",
    "        edge = [abs(x - y)**2 for x,y in zip(node_emb_1, node_emb_2)]\n",
    "    elif operator == 'Concat':\n",
    "        edge = np.concatenate((node_emb_1, node_emb_2), axis=None) \n",
    "    else:\n",
    "        print(\"Generate edge features: Operator not supported\")\n",
    "        print(\"Use default operator: Weighted-L1\")\n",
    "        edge = [abs(x - y) for x,y in zip(node_emb_1, node_emb_2)]\n",
    "        \n",
    "    return edge\n",
    "def generate_edge_features(edge_list, node_embeddings, operator):\n",
    "    edge_features_mtx = []\n",
    "    \n",
    "    # generate features for each edge in the list\n",
    "    for node_index_1, node_index_2 in edge_list:\n",
    "        node_emb_1 = node_embeddings[node_index_1-1]\n",
    "        node_emb_2 = node_embeddings[node_index_2-1]\n",
    "        \n",
    "        edge_features_mtx.append(edge_features(node_emb_1, node_emb_2, operator))\n",
    "        \n",
    "    return edge_features_mtx\n",
    "\n",
    "def generate_train_set(graph_train, num_edge_sample, node_embeddings, edge_operator,):\n",
    "    edge_list = list(graph_train.edges)\n",
    "    num_nodes = graph_train.number_of_nodes()\n",
    "    \n",
    "    train_edges = []\n",
    "    train_edges_labels = [1] * num_edge_sample + [0] * num_edge_sample\n",
    "    \n",
    "    random.seed(0)\n",
    "    \n",
    "    # sample edges with label 1 (true edges)\n",
    "    for edge_num in range(num_edge_sample):\n",
    "        rand_index = random.randint(0, len(edge_list) - 1)\n",
    "        \n",
    "        #train_edges.append(tuple(edge_list[rand_index]))\n",
    "        train_edges.append(edge_list[rand_index])\n",
    "    non_edge_num = 0\n",
    "    \n",
    "    # sample edges with label 0 (non-exist edges)\n",
    "    while(non_edge_num < num_edge_sample):\n",
    "        rand_nodes = tuple(np.random.randint(low=0,high=num_nodes, size=2))\n",
    "        \n",
    "        if rand_nodes not in edge_list:\n",
    "            train_edges.append(rand_nodes)\n",
    "            non_edge_num += 1\n",
    "\n",
    "    train_edges_features_mtx = generate_edge_features(train_edges, node_embeddings, edge_operator)\n",
    "            \n",
    "    return train_edges, train_edges_features_mtx, train_edges_labels\n",
    "\n",
    "def generate_test_set(graph_test, node_embeddings, edge_operator):\n",
    "    edge_list = graph_test.edges\n",
    "    nodes_with_edge = set()\n",
    "    \n",
    "    for edge in edge_list:\n",
    "        nodes_with_edge.add(edge[0])\n",
    "        nodes_with_edge.add(edge[1])\n",
    "    \n",
    "    num_nodes = graph_test.number_of_nodes()\n",
    "    \n",
    "    test_edges = []\n",
    "    test_edges_labels = []\n",
    "    \n",
    "    num_edge_sample = len(edge_list)\n",
    "    non_edge_num = 0 \n",
    "    # sample edges with label 0 (non-exist edges)\n",
    "    \n",
    "    while(non_edge_num < num_edge_sample):\n",
    "        rand_nodes = tuple(np.random.randint(low=0,high=num_nodes, size=2))\n",
    "        \n",
    "        if rand_nodes not in edge_list:\n",
    "            test_edges.append(rand_nodes)\n",
    "            test_edges_labels.append(0)\n",
    "            non_edge_num += 1\n",
    "        \n",
    "    for edge in edge_list:\n",
    "        test_edges.append(edge)\n",
    "        test_edges_labels.append(1)\n",
    "    \n",
    "    test_edges_features_mtx = generate_edge_features(test_edges, node_embeddings, edge_operator)\n",
    "    \n",
    "    return test_edges, test_edges_features_mtx, test_edges_labels\n",
    "\n",
    "def build_clf(feature_mtx, response_vec):\n",
    "   \n",
    "    logistic_regression_model = LogisticRegression(random_state = 0,max_iter=5000,solver='liblinear',verbose=1,tol=1e-6)\n",
    "    binary_clf = logistic_regression_model.fit(feature_mtx, response_vec)\n",
    "    \n",
    "    return binary_clf\n",
    "\n",
    "def pred_links(feature_mtx, LR_clf):\n",
    "    predict_edges_labels = LR_clf.predict(feature_mtx)\n",
    "    \n",
    "    return predict_edges_labels\n",
    "\n",
    "def precision_recall(predict_labels, true_labels):\n",
    "    true_positive  = false_positive = 0\n",
    "    true_negative =  false_negative = 0\n",
    "    \n",
    "    for p_label, true_label in zip(predict_labels, true_labels):\n",
    "        \n",
    "        #print(p_label,true_label)\n",
    "        if p_label == true_label and true_label == 1:\n",
    "            true_positive += 1\n",
    "        elif p_label == true_label and true_label == 0:\n",
    "            true_negative += 1\n",
    "        elif p_label != true_label and true_label == 1:\n",
    "            false_negative += 1\n",
    "        elif p_label != true_label and true_label == 0:\n",
    "            false_positive += 1\n",
    "\n",
    "    print(\"TP: \", true_positive)\n",
    "    print(\"TN: \", true_negative)\n",
    "    print(\"FP: \", false_positive)\n",
    "    print(\"FN: \", false_negative)\n",
    "    \n",
    "    precision = recall = 0\n",
    "    try:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "        if (precision + recall) != 0.0:\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "            print(\"F1: {}\".format(f1))            \n",
    "    except:\n",
    "        print(\"F1: Divide-by-zero\")\n",
    "    \n",
    "    cm = metrics.confusion_matrix(true_labels, predict_labels)\n",
    "    print(cm)\n",
    "    print(metrics.classification_report(true_labels, predict_labels))\n",
    "    map = metrics.average_precision_score(true_labels, predict_labels)\n",
    "    print('Mean Average Precision: {}'.format(map))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(true_labels, predict_labels)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    print('Area Under ROC Curve: {}'.format(roc_auc))\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RM- Monthly\n",
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and testing graph\n",
    "with open('../RM_monthly.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]\n",
    "\n",
    "# parameters\n",
    "num_edge_sample = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_snapshots = len(graphs)\n",
    "num_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "emb_list = []\n",
    "for i in range(num_snapshots):\n",
    "    file = '../RM_N2V_emb/vc_month_emb/vc_month_' + str(i) + '.npy'\n",
    "    node_embedding = np.load(file)\n",
    "    emb_list.append(node_embedding)\n",
    "print(len(emb_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### independent / no combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings_training = emb_list[-3]\n",
    "node_embeddings_testing = emb_list[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  0\n",
      "TN:  222\n",
      "FP:  0\n",
      "FN:  222\n",
      "F1: Divide-by-zero\n",
      "[[222   0]\n",
      " [222   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       222\n",
      "           1       0.00      0.00      0.00       222\n",
      "\n",
      "    accuracy                           0.50       444\n",
      "   macro avg       0.25      0.50      0.33       444\n",
      "weighted avg       0.25      0.50      0.33       444\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  103\n",
      "TN:  221\n",
      "FP:  1\n",
      "FN:  119\n",
      "F1: 0.6319018404907976\n",
      "[[221   1]\n",
      " [119 103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79       222\n",
      "           1       0.99      0.46      0.63       222\n",
      "\n",
      "    accuracy                           0.73       444\n",
      "   macro avg       0.82      0.73      0.71       444\n",
      "weighted avg       0.82      0.73      0.71       444\n",
      "\n",
      "Mean Average Precision: 0.7275207900207901\n",
      "Area Under ROC Curve: 0.7297297297297297\n",
      "Precision:  0.9903846153846154\n",
      "Recall:  0.46396396396396394\n",
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  168\n",
      "TN:  203\n",
      "FP:  19\n",
      "FN:  54\n",
      "F1: 0.821515892420538\n",
      "[[203  19]\n",
      " [ 54 168]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85       222\n",
      "           1       0.90      0.76      0.82       222\n",
      "\n",
      "    accuracy                           0.84       444\n",
      "   macro avg       0.84      0.84      0.83       444\n",
      "weighted avg       0.84      0.84      0.83       444\n",
      "\n",
      "Mean Average Precision: 0.801488654429831\n",
      "Area Under ROC Curve: 0.8355855855855856\n",
      "Precision:  0.8983957219251337\n",
      "Recall:  0.7567567567567568\n",
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  130\n",
      "TN:  202\n",
      "FP:  20\n",
      "FN:  92\n",
      "F1: 0.6989247311827956\n",
      "[[202  20]\n",
      " [ 92 130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.91      0.78       222\n",
      "           1       0.87      0.59      0.70       222\n",
      "\n",
      "    accuracy                           0.75       444\n",
      "   macro avg       0.78      0.75      0.74       444\n",
      "weighted avg       0.78      0.75      0.74       444\n",
      "\n",
      "Mean Average Precision: 0.7147147147147147\n",
      "Area Under ROC Curve: 0.7477477477477478\n",
      "Precision:  0.8666666666666667\n",
      "Recall:  0.5855855855855856\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  0\n",
      "TN:  222\n",
      "FP:  0\n",
      "FN:  222\n",
      "F1: Divide-by-zero\n",
      "[[222   0]\n",
      " [222   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       222\n",
      "           1       0.00      0.00      0.00       222\n",
      "\n",
      "    accuracy                           0.50       444\n",
      "   macro avg       0.25      0.50      0.33       444\n",
      "weighted avg       0.25      0.50      0.33       444\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(emb_list)):\n",
    "    emb_list[i] = np.asfarray(emb_list[i],float)\n",
    "node_embeddings_training = np.sum(np.asarray(emb_list[0:-2]),axis=0)\n",
    "node_embeddings_testing = np.sum(np.asarray(emb_list[0:-1]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  222\n",
      "TN:  211\n",
      "FP:  11\n",
      "FN:  0\n",
      "F1: 0.9758241758241758\n",
      "[[211  11]\n",
      " [  0 222]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       222\n",
      "           1       0.95      1.00      0.98       222\n",
      "\n",
      "    accuracy                           0.98       444\n",
      "   macro avg       0.98      0.98      0.98       444\n",
      "weighted avg       0.98      0.98      0.98       444\n",
      "\n",
      "Mean Average Precision: 0.9527896995708155\n",
      "Area Under ROC Curve: 0.9752252252252251\n",
      "Precision:  0.9527896995708155\n",
      "Recall:  1.0\n",
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  137\n",
      "TN:  201\n",
      "FP:  21\n",
      "FN:  85\n",
      "F1: 0.7210526315789474\n",
      "[[201  21]\n",
      " [ 85 137]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.91      0.79       222\n",
      "           1       0.87      0.62      0.72       222\n",
      "\n",
      "    accuracy                           0.76       444\n",
      "   macro avg       0.78      0.76      0.76       444\n",
      "weighted avg       0.78      0.76      0.76       444\n",
      "\n",
      "Mean Average Precision: 0.7265366632455239\n",
      "Area Under ROC Curve: 0.7612612612612613\n",
      "Precision:  0.8670886075949367\n",
      "Recall:  0.6171171171171171\n",
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  158\n",
      "TN:  202\n",
      "FP:  20\n",
      "FN:  64\n",
      "F1: 0.7899999999999999\n",
      "[[202  20]\n",
      " [ 64 158]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83       222\n",
      "           1       0.89      0.71      0.79       222\n",
      "\n",
      "    accuracy                           0.81       444\n",
      "   macro avg       0.82      0.81      0.81       444\n",
      "weighted avg       0.82      0.81      0.81       444\n",
      "\n",
      "Mean Average Precision: 0.7758882477983602\n",
      "Area Under ROC Curve: 0.8108108108108107\n",
      "Precision:  0.8876404494382022\n",
      "Recall:  0.7117117117117117\n",
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  135\n",
      "TN:  197\n",
      "FP:  25\n",
      "FN:  87\n",
      "F1: 0.7068062827225131\n",
      "[[197  25]\n",
      " [ 87 135]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.78       222\n",
      "           1       0.84      0.61      0.71       222\n",
      "\n",
      "    accuracy                           0.75       444\n",
      "   macro avg       0.77      0.75      0.74       444\n",
      "weighted avg       0.77      0.75      0.74       444\n",
      "\n",
      "Mean Average Precision: 0.7090371621621622\n",
      "Area Under ROC Curve: 0.7477477477477478\n",
      "Precision:  0.84375\n",
      "Recall:  0.6081081081081081\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  222\n",
      "TN:  220\n",
      "FP:  2\n",
      "FN:  0\n",
      "F1: 0.9955156950672646\n",
      "[[220   2]\n",
      " [  0 222]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       222\n",
      "           1       0.99      1.00      1.00       222\n",
      "\n",
      "    accuracy                           1.00       444\n",
      "   macro avg       1.00      1.00      1.00       444\n",
      "weighted avg       1.00      1.00      1.00       444\n",
      "\n",
      "Mean Average Precision: 0.9910714285714286\n",
      "Area Under ROC Curve: 0.9954954954954954\n",
      "Precision:  0.9910714285714286\n",
      "Recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in ['Average', 'Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expdecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [np.exp(-i * 0.3) for i in range(1,17)]\n",
    "node_embeddings_training = np.zeros((emb_list[0]).shape) \n",
    "for c,e in zip(emb_list[0:-2],exps[:-1]):\n",
    "    node_embeddings_training += e * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings_testing = np.zeros((emb_list[0]).shape) \n",
    "for c,e in zip(emb_list[0:-1],exps[:-1]):\n",
    "    node_embeddings_testing += e * c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  222\n",
      "TN:  210\n",
      "FP:  12\n",
      "FN:  0\n",
      "F1: 0.9736842105263158\n",
      "[[210  12]\n",
      " [  0 222]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       222\n",
      "           1       0.95      1.00      0.97       222\n",
      "\n",
      "    accuracy                           0.97       444\n",
      "   macro avg       0.97      0.97      0.97       444\n",
      "weighted avg       0.97      0.97      0.97       444\n",
      "\n",
      "Mean Average Precision: 0.9487179487179487\n",
      "Area Under ROC Curve: 0.972972972972973\n",
      "Precision:  0.9487179487179487\n",
      "Recall:  1.0\n",
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  114\n",
      "TN:  213\n",
      "FP:  9\n",
      "FN:  108\n",
      "F1: 0.6608695652173913\n",
      "[[213   9]\n",
      " [108 114]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.96      0.78       222\n",
      "           1       0.93      0.51      0.66       222\n",
      "\n",
      "    accuracy                           0.74       444\n",
      "   macro avg       0.80      0.74      0.72       444\n",
      "weighted avg       0.80      0.74      0.72       444\n",
      "\n",
      "Mean Average Precision: 0.7191825972313777\n",
      "Area Under ROC Curve: 0.7364864864864865\n",
      "Precision:  0.926829268292683\n",
      "Recall:  0.5135135135135135\n",
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  189\n",
      "TN:  208\n",
      "FP:  14\n",
      "FN:  33\n",
      "F1: 0.8894117647058823\n",
      "[[208  14]\n",
      " [ 33 189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90       222\n",
      "           1       0.93      0.85      0.89       222\n",
      "\n",
      "    accuracy                           0.89       444\n",
      "   macro avg       0.90      0.89      0.89       444\n",
      "weighted avg       0.90      0.89      0.89       444\n",
      "\n",
      "Mean Average Precision: 0.8669617893755824\n",
      "Area Under ROC Curve: 0.8941441441441441\n",
      "Precision:  0.9310344827586207\n",
      "Recall:  0.8513513513513513\n",
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  175\n",
      "TN:  207\n",
      "FP:  15\n",
      "FN:  47\n",
      "F1: 0.8495145631067961\n",
      "[[207  15]\n",
      " [ 47 175]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       222\n",
      "           1       0.92      0.79      0.85       222\n",
      "\n",
      "    accuracy                           0.86       444\n",
      "   macro avg       0.87      0.86      0.86       444\n",
      "weighted avg       0.87      0.86      0.86       444\n",
      "\n",
      "Mean Average Precision: 0.8319108582266477\n",
      "Area Under ROC Curve: 0.8603603603603605\n",
      "Precision:  0.9210526315789473\n",
      "Recall:  0.7882882882882883\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  222\n",
      "TN:  218\n",
      "FP:  4\n",
      "FN:  0\n",
      "F1: 0.9910714285714286\n",
      "[[218   4]\n",
      " [  0 222]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       222\n",
      "           1       0.98      1.00      0.99       222\n",
      "\n",
      "    accuracy                           0.99       444\n",
      "   macro avg       0.99      0.99      0.99       444\n",
      "weighted avg       0.99      0.99      0.99       444\n",
      "\n",
      "Mean Average Precision: 0.9823008849557522\n",
      "Area Under ROC Curve: 0.990990990990991\n",
      "Precision:  0.9823008849557522\n",
      "Recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in [ 'Average', 'Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RM - Weekly\n",
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and testing graph\n",
    "with open('../RM_weekly.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]\n",
    "\n",
    "# parameters\n",
    "num_edge_sample = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_snapshots = len(graphs)\n",
    "num_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "emb_list = []\n",
    "for i in range(num_snapshots):\n",
    "    file = '../RM_N2V_emb/vc_week_emb/vc_week_' + str(i) + '.npy'\n",
    "    node_embedding = np.load(file)\n",
    "    emb_list.append(node_embedding)\n",
    "print(len(emb_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### independent / no combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings_training = emb_list[-3]\n",
    "node_embeddings_testing = emb_list[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  0\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  14\n",
      "F1: Divide-by-zero\n",
      "[[14  0]\n",
      " [14  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        14\n",
      "           1       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.50        28\n",
      "   macro avg       0.25      0.50      0.33        28\n",
      "weighted avg       0.25      0.50      0.33        28\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  10\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  4\n",
      "F1: 0.8333333333333333\n",
      "[[14  0]\n",
      " [ 4 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        14\n",
      "           1       1.00      0.71      0.83        14\n",
      "\n",
      "    accuracy                           0.86        28\n",
      "   macro avg       0.89      0.86      0.85        28\n",
      "weighted avg       0.89      0.86      0.85        28\n",
      "\n",
      "Mean Average Precision: 0.8571428571428572\n",
      "Area Under ROC Curve: 0.8571428571428572\n",
      "Precision:  1.0\n",
      "Recall:  0.7142857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  11\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  3\n",
      "F1: 0.88\n",
      "[[14  0]\n",
      " [ 3 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        14\n",
      "           1       1.00      0.79      0.88        14\n",
      "\n",
      "    accuracy                           0.89        28\n",
      "   macro avg       0.91      0.89      0.89        28\n",
      "weighted avg       0.91      0.89      0.89        28\n",
      "\n",
      "Mean Average Precision: 0.8928571428571428\n",
      "Area Under ROC Curve: 0.8928571428571428\n",
      "Precision:  1.0\n",
      "Recall:  0.7857142857142857\n",
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  4\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  10\n",
      "F1: 0.4444444444444445\n",
      "[[14  0]\n",
      " [10  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.74        14\n",
      "           1       1.00      0.29      0.44        14\n",
      "\n",
      "    accuracy                           0.64        28\n",
      "   macro avg       0.79      0.64      0.59        28\n",
      "weighted avg       0.79      0.64      0.59        28\n",
      "\n",
      "Mean Average Precision: 0.6428571428571428\n",
      "Area Under ROC Curve: 0.6428571428571428\n",
      "Precision:  1.0\n",
      "Recall:  0.2857142857142857\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  0\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  14\n",
      "F1: Divide-by-zero\n",
      "[[14  0]\n",
      " [14  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        14\n",
      "           1       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.50        28\n",
      "   macro avg       0.25      0.50      0.33        28\n",
      "weighted avg       0.25      0.50      0.33        28\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in ['Average', 'Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(emb_list)):\n",
    "    emb_list[i] = np.asfarray(emb_list[i],float)\n",
    "node_embeddings_training = np.sum(np.asarray(emb_list[0:-2]),axis=0)\n",
    "node_embeddings_testing = np.sum(np.asarray(emb_list[0:-1]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  14\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  0\n",
      "F1: 1.0\n",
      "[[14  0]\n",
      " [ 0 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Mean Average Precision: 1.0\n",
      "Area Under ROC Curve: 1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  13\n",
      "TN:  12\n",
      "FP:  2\n",
      "FN:  1\n",
      "F1: 0.896551724137931\n",
      "[[12  2]\n",
      " [ 1 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89        14\n",
      "           1       0.87      0.93      0.90        14\n",
      "\n",
      "    accuracy                           0.89        28\n",
      "   macro avg       0.89      0.89      0.89        28\n",
      "weighted avg       0.89      0.89      0.89        28\n",
      "\n",
      "Mean Average Precision: 0.8404761904761905\n",
      "Area Under ROC Curve: 0.8928571428571429\n",
      "Precision:  0.8666666666666667\n",
      "Recall:  0.9285714285714286\n",
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  14\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  0\n",
      "F1: 1.0\n",
      "[[14  0]\n",
      " [ 0 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Mean Average Precision: 1.0\n",
      "Area Under ROC Curve: 1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  14\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  0\n",
      "F1: 1.0\n",
      "[[14  0]\n",
      " [ 0 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Mean Average Precision: 1.0\n",
      "Area Under ROC Curve: 1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  14\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  0\n",
      "F1: 1.0\n",
      "[[14  0]\n",
      " [ 0 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Mean Average Precision: 1.0\n",
      "Area Under ROC Curve: 1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in ['Average', 'Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expdecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [np.exp(-i * 0.9) for i in range(1,74)]\n",
    "node_embeddings_training = np.zeros((emb_list[0]).shape) \n",
    "for c,e in zip(emb_list[0:-2],exps[:-1]):\n",
    "    node_embeddings_training += e * c \n",
    "node_embeddings_testing = np.zeros((emb_list[0]).shape) \n",
    "for c,e in zip(emb_list[0:-1],exps[:-1]):\n",
    "    node_embeddings_testing += e * c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  1\n",
      "TN:  13\n",
      "FP:  1\n",
      "FN:  13\n",
      "F1: 0.125\n",
      "[[13  1]\n",
      " [13  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.93      0.65        14\n",
      "           1       0.50      0.07      0.12        14\n",
      "\n",
      "    accuracy                           0.50        28\n",
      "   macro avg       0.50      0.50      0.39        28\n",
      "weighted avg       0.50      0.50      0.39        28\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0.5\n",
      "Recall:  0.07142857142857142\n",
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  1\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  13\n",
      "F1: 0.13333333333333333\n",
      "[[14  0]\n",
      " [13  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.68        14\n",
      "           1       1.00      0.07      0.13        14\n",
      "\n",
      "    accuracy                           0.54        28\n",
      "   macro avg       0.76      0.54      0.41        28\n",
      "weighted avg       0.76      0.54      0.41        28\n",
      "\n",
      "Mean Average Precision: 0.5357142857142857\n",
      "Area Under ROC Curve: 0.5357142857142857\n",
      "Precision:  1.0\n",
      "Recall:  0.07142857142857142\n",
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  1\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  13\n",
      "F1: 0.13333333333333333\n",
      "[[14  0]\n",
      " [13  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.68        14\n",
      "           1       1.00      0.07      0.13        14\n",
      "\n",
      "    accuracy                           0.54        28\n",
      "   macro avg       0.76      0.54      0.41        28\n",
      "weighted avg       0.76      0.54      0.41        28\n",
      "\n",
      "Mean Average Precision: 0.5357142857142857\n",
      "Area Under ROC Curve: 0.5357142857142857\n",
      "Precision:  1.0\n",
      "Recall:  0.07142857142857142\n",
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  1\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  13\n",
      "F1: 0.13333333333333333\n",
      "[[14  0]\n",
      " [13  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.68        14\n",
      "           1       1.00      0.07      0.13        14\n",
      "\n",
      "    accuracy                           0.54        28\n",
      "   macro avg       0.76      0.54      0.41        28\n",
      "weighted avg       0.76      0.54      0.41        28\n",
      "\n",
      "Mean Average Precision: 0.5357142857142857\n",
      "Area Under ROC Curve: 0.5357142857142857\n",
      "Precision:  1.0\n",
      "Recall:  0.07142857142857142\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  1\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  13\n",
      "F1: 0.13333333333333333\n",
      "[[14  0]\n",
      " [13  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.68        14\n",
      "           1       1.00      0.07      0.13        14\n",
      "\n",
      "    accuracy                           0.54        28\n",
      "   macro avg       0.76      0.54      0.41        28\n",
      "weighted avg       0.76      0.54      0.41        28\n",
      "\n",
      "Mean Average Precision: 0.5357142857142857\n",
      "Area Under ROC Curve: 0.5357142857142857\n",
      "Precision:  1.0\n",
      "Recall:  0.07142857142857142\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in ['Average', 'Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email-EU - Equal Monthly\n",
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and testing graph\n",
    "with open('../RM_weekly.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]\n",
    "\n",
    "# parameters\n",
    "num_edge_sample = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_snapshots = len(graphs)\n",
    "num_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "emb_list = []\n",
    "for i in range(num_snapshots):\n",
    "    file = '../RM_emb/em-vc-week/em-vc-week-' + str(i) + '.npy'\n",
    "    node_embedding = np.load(file)\n",
    "    emb_list.append(node_embedding)\n",
    "print(len(emb_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### independent / no combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings_training = emb_list[-3]\n",
    "node_embeddings_testing = emb_list[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  0\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  14\n",
      "F1: Divide-by-zero\n",
      "[[14  0]\n",
      " [14  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        14\n",
      "           1       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.50        28\n",
      "   macro avg       0.25      0.50      0.33        28\n",
      "weighted avg       0.25      0.50      0.33        28\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  3\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  11\n",
      "F1: 0.35294117647058826\n",
      "[[14  0]\n",
      " [11  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.72        14\n",
      "           1       1.00      0.21      0.35        14\n",
      "\n",
      "    accuracy                           0.61        28\n",
      "   macro avg       0.78      0.61      0.54        28\n",
      "weighted avg       0.78      0.61      0.54        28\n",
      "\n",
      "Mean Average Precision: 0.6071428571428571\n",
      "Area Under ROC Curve: 0.6071428571428571\n",
      "Precision:  1.0\n",
      "Recall:  0.21428571428571427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  0\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  14\n",
      "F1: Divide-by-zero\n",
      "[[14  0]\n",
      " [14  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        14\n",
      "           1       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.50        28\n",
      "   macro avg       0.25      0.50      0.33        28\n",
      "weighted avg       0.25      0.50      0.33        28\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  0\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  14\n",
      "F1: Divide-by-zero\n",
      "[[14  0]\n",
      " [14  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        14\n",
      "           1       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.50        28\n",
      "   macro avg       0.25      0.50      0.33        28\n",
      "weighted avg       0.25      0.50      0.33        28\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  0\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  14\n",
      "F1: Divide-by-zero\n",
      "[[14  0]\n",
      " [14  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        14\n",
      "           1       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.50        28\n",
      "   macro avg       0.25      0.50      0.33        28\n",
      "weighted avg       0.25      0.50      0.33        28\n",
      "\n",
      "Mean Average Precision: 0.5\n",
      "Area Under ROC Curve: 0.5\n",
      "Precision:  0\n",
      "Recall:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(emb_list)):\n",
    "    emb_list[i] = np.asfarray(emb_list[i],float)\n",
    "node_embeddings_training = np.sum(np.asarray(emb_list[0:-2]),axis=0)\n",
    "node_embeddings_testing = np.sum(np.asarray(emb_list[0:-1]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  14\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  0\n",
      "F1: 1.0\n",
      "[[14  0]\n",
      " [ 0 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Mean Average Precision: 1.0\n",
      "Area Under ROC Curve: 1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  9\n",
      "TN:  13\n",
      "FP:  1\n",
      "FN:  5\n",
      "F1: 0.75\n",
      "[[13  1]\n",
      " [ 5  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81        14\n",
      "           1       0.90      0.64      0.75        14\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.81      0.79      0.78        28\n",
      "weighted avg       0.81      0.79      0.78        28\n",
      "\n",
      "Mean Average Precision: 0.7571428571428571\n",
      "Area Under ROC Curve: 0.7857142857142857\n",
      "Precision:  0.9\n",
      "Recall:  0.6428571428571429\n",
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  14\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  0\n",
      "F1: 1.0\n",
      "[[14  0]\n",
      " [ 0 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Mean Average Precision: 1.0\n",
      "Area Under ROC Curve: 1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  14\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  0\n",
      "F1: 1.0\n",
      "[[14  0]\n",
      " [ 0 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Mean Average Precision: 1.0\n",
      "Area Under ROC Curve: 1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  14\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  0\n",
      "F1: 1.0\n",
      "[[14  0]\n",
      " [ 0 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Mean Average Precision: 1.0\n",
      "Area Under ROC Curve: 1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in ['Average', 'Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expdecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [np.exp(-i * 0.9) for i in range(1,17)]\n",
    "node_embeddings_training = np.zeros((emb_list[0]).shape) \n",
    "for c,e in zip(emb_list[0:-2],exps[:-1]):\n",
    "    node_embeddings_training += e * c \n",
    "node_embeddings_testing = np.zeros((emb_list[0]).shape) \n",
    "for c,e in zip(emb_list[0:-1],exps[:-1]):\n",
    "    node_embeddings_testing += e * c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  14\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  0\n",
      "F1: 1.0\n",
      "[[14  0]\n",
      " [ 0 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Mean Average Precision: 1.0\n",
      "Area Under ROC Curve: 1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  10\n",
      "TN:  13\n",
      "FP:  1\n",
      "FN:  4\n",
      "F1: 0.8\n",
      "[[13  1]\n",
      " [ 4 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.84        14\n",
      "           1       0.91      0.71      0.80        14\n",
      "\n",
      "    accuracy                           0.82        28\n",
      "   macro avg       0.84      0.82      0.82        28\n",
      "weighted avg       0.84      0.82      0.82        28\n",
      "\n",
      "Mean Average Precision: 0.7922077922077921\n",
      "Area Under ROC Curve: 0.8214285714285715\n",
      "Precision:  0.9090909090909091\n",
      "Recall:  0.7142857142857143\n",
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  14\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  0\n",
      "F1: 1.0\n",
      "[[14  0]\n",
      " [ 0 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Mean Average Precision: 1.0\n",
      "Area Under ROC Curve: 1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  13\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  1\n",
      "F1: 0.962962962962963\n",
      "[[14  0]\n",
      " [ 1 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        14\n",
      "           1       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.96        28\n",
      "   macro avg       0.97      0.96      0.96        28\n",
      "weighted avg       0.97      0.96      0.96        28\n",
      "\n",
      "Mean Average Precision: 0.9642857142857143\n",
      "Area Under ROC Curve: 0.9642857142857143\n",
      "Precision:  1.0\n",
      "Recall:  0.9285714285714286\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  14\n",
      "TN:  14\n",
      "FP:  0\n",
      "FN:  0\n",
      "F1: 1.0\n",
      "[[14  0]\n",
      " [ 0 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        28\n",
      "   macro avg       1.00      1.00      1.00        28\n",
      "weighted avg       1.00      1.00      1.00        28\n",
      "\n",
      "Mean Average Precision: 1.0\n",
      "Area Under ROC Curve: 1.0\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in ['Average', 'Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email-EU - Equal Weekly\n",
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and testing graph\n",
    "with open('../data/email_EU/email_equal_weekly_dir.pkl', 'rb') as file:\n",
    "    graphs = pickle.load(file)\n",
    "graph_train = graphs[-2]\n",
    "graph_test = graphs[-1]\n",
    "\n",
    "# parameters\n",
    "num_edge_sample = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_snapshots = len(graphs)\n",
    "num_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "emb_list = []\n",
    "for i in range(num_snapshots):\n",
    "    file = '../data/email_EU/embeddings/em-email-equal-week-' + str(i) + '.npy'\n",
    "    node_embedding = np.load(file)\n",
    "    emb_list.append(node_embedding)\n",
    "print(len(emb_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings_training = emb_list[-3]\n",
    "node_embeddings_testing = emb_list[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  242\n",
      "TN:  1948\n",
      "FP:  197\n",
      "FN:  1903\n",
      "F1: 0.1873065015479876\n",
      "[[1948  197]\n",
      " [1903  242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.91      0.65      2145\n",
      "           1       0.55      0.11      0.19      2145\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      4290\n",
      "   macro avg       0.53      0.51      0.42      4290\n",
      "weighted avg       0.53      0.51      0.42      4290\n",
      "\n",
      "Mean Average Precision: 0.5057823725249693\n",
      "Area Under ROC Curve: 0.5104895104895105\n",
      "Precision:  0.55125284738041\n",
      "Recall:  0.11282051282051282\n",
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  1673\n",
      "TN:  427\n",
      "FP:  1718\n",
      "FN:  472\n",
      "F1: 0.604407514450867\n",
      "[[ 427 1718]\n",
      " [ 472 1673]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.20      0.28      2145\n",
      "           1       0.49      0.78      0.60      2145\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      4290\n",
      "   macro avg       0.48      0.49      0.44      4290\n",
      "weighted avg       0.48      0.49      0.44      4290\n",
      "\n",
      "Mean Average Precision: 0.49482484486907957\n",
      "Area Under ROC Curve: 0.48951048951048953\n",
      "Precision:  0.493364789147744\n",
      "Recall:  0.77995337995338\n",
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  1154\n",
      "TN:  992\n",
      "FP:  1153\n",
      "FN:  991\n",
      "F1: 0.5184186882300089\n",
      "[[ 992 1153]\n",
      " [ 991 1154]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.46      0.48      2145\n",
      "           1       0.50      0.54      0.52      2145\n",
      "\n",
      "   micro avg       0.50      0.50      0.50      4290\n",
      "   macro avg       0.50      0.50      0.50      4290\n",
      "weighted avg       0.50      0.50      0.50      4290\n",
      "\n",
      "Mean Average Precision: 0.5001166006367567\n",
      "Area Under ROC Curve: 0.5002331002331002\n",
      "Precision:  0.5002167316861725\n",
      "Recall:  0.5379953379953379\n",
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  1175\n",
      "TN:  1016\n",
      "FP:  1129\n",
      "FN:  970\n",
      "F1: 0.5282085861991458\n",
      "[[1016 1129]\n",
      " [ 970 1175]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.47      0.49      2145\n",
      "           1       0.51      0.55      0.53      2145\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      4290\n",
      "   macro avg       0.51      0.51      0.51      4290\n",
      "weighted avg       0.51      0.51      0.51      4290\n",
      "\n",
      "Mean Average Precision: 0.5054683453120953\n",
      "Area Under ROC Curve: 0.5107226107226107\n",
      "Precision:  0.5099826388888888\n",
      "Recall:  0.5477855477855478\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  893\n",
      "TN:  1278\n",
      "FP:  867\n",
      "FN:  1252\n",
      "F1: 0.4573623559539053\n",
      "[[1278  867]\n",
      " [1252  893]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.60      0.55      2145\n",
      "           1       0.51      0.42      0.46      2145\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      4290\n",
      "   macro avg       0.51      0.51      0.50      4290\n",
      "weighted avg       0.51      0.51      0.50      4290\n",
      "\n",
      "Mean Average Precision: 0.5030750688705234\n",
      "Area Under ROC Curve: 0.5060606060606061\n",
      "Precision:  0.5073863636363637\n",
      "Recall:  0.41631701631701634\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in ['Average','Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(emb_list)):\n",
    "    emb_list[i] = np.asfarray(emb_list[i],float)\n",
    "node_embeddings_training = np.sum(np.asarray(emb_list[0:-2]),axis=0)\n",
    "node_embeddings_testing = np.sum(np.asarray(emb_list[0:-1]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  1281\n",
      "TN:  1369\n",
      "FP:  776\n",
      "FN:  864\n",
      "F1: 0.609709662065683\n",
      "[[1369  776]\n",
      " [ 864 1281]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.63      2145\n",
      "           1       0.62      0.60      0.61      2145\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      4290\n",
      "   macro avg       0.62      0.62      0.62      4290\n",
      "weighted avg       0.62      0.62      0.62      4290\n",
      "\n",
      "Mean Average Precision: 0.5733075869196433\n",
      "Area Under ROC Curve: 0.6177156177156178\n",
      "Precision:  0.6227515799708313\n",
      "Recall:  0.5972027972027972\n",
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  1237\n",
      "TN:  1017\n",
      "FP:  1128\n",
      "FN:  908\n",
      "F1: 0.5485587583148559\n",
      "[[1017 1128]\n",
      " [ 908 1237]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.47      0.50      2145\n",
      "           1       0.52      0.58      0.55      2145\n",
      "\n",
      "   micro avg       0.53      0.53      0.53      4290\n",
      "   macro avg       0.53      0.53      0.52      4290\n",
      "weighted avg       0.53      0.53      0.52      4290\n",
      "\n",
      "Mean Average Precision: 0.5132894730357733\n",
      "Area Under ROC Curve: 0.5254079254079254\n",
      "Precision:  0.5230443974630021\n",
      "Recall:  0.5766899766899767\n",
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  1136\n",
      "TN:  1247\n",
      "FP:  898\n",
      "FN:  1009\n",
      "F1: 0.5436707346255085\n",
      "[[1247  898]\n",
      " [1009 1136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.58      0.57      2145\n",
      "           1       0.56      0.53      0.54      2145\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      4290\n",
      "   macro avg       0.56      0.56      0.56      4290\n",
      "weighted avg       0.56      0.56      0.56      4290\n",
      "\n",
      "Mean Average Precision: 0.5309846823121159\n",
      "Area Under ROC Curve: 0.5554778554778556\n",
      "Precision:  0.5585054080629301\n",
      "Recall:  0.5296037296037296\n",
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  1253\n",
      "TN:  1155\n",
      "FP:  990\n",
      "FN:  892\n",
      "F1: 0.5711030082041932\n",
      "[[1155  990]\n",
      " [ 892 1253]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.54      0.55      2145\n",
      "           1       0.56      0.58      0.57      2145\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      4290\n",
      "   macro avg       0.56      0.56      0.56      4290\n",
      "weighted avg       0.56      0.56      0.56      4290\n",
      "\n",
      "Mean Average Precision: 0.5342468202031287\n",
      "Area Under ROC Curve: 0.5613053613053613\n",
      "Precision:  0.5586268390548372\n",
      "Recall:  0.5841491841491842\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  1261\n",
      "TN:  1259\n",
      "FP:  886\n",
      "FN:  884\n",
      "F1: 0.587604846225536\n",
      "[[1259  886]\n",
      " [ 884 1261]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59      2145\n",
      "           1       0.59      0.59      0.59      2145\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      4290\n",
      "   macro avg       0.59      0.59      0.59      4290\n",
      "weighted avg       0.59      0.59      0.59      4290\n",
      "\n",
      "Mean Average Precision: 0.5513401363424653\n",
      "Area Under ROC Curve: 0.5874125874125874\n",
      "Precision:  0.5873311597578016\n",
      "Recall:  0.5878787878787879\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in ['Average', 'Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expdecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [np.exp(-i * 0.3) for i in range(1,28)]\n",
    "node_embeddings_training = np.zeros((emb_list[0]).shape) \n",
    "for c,e in zip(emb_list[0:-2],exps[:-1]):\n",
    "    node_embeddings_training += e * c \n",
    "node_embeddings_testing = np.zeros((emb_list[0]).shape) \n",
    "for c,e in zip(emb_list[0:-1],exps[:-1]):\n",
    "    node_embeddings_testing += e * c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Edge Operator: Average\n",
      "TP:  1306\n",
      "TN:  1276\n",
      "FP:  869\n",
      "FN:  839\n",
      "F1: 0.6046296296296296\n",
      "[[1276  869]\n",
      " [ 839 1306]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.60      2145\n",
      "           1       0.60      0.61      0.60      2145\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      4290\n",
      "   macro avg       0.60      0.60      0.60      4290\n",
      "weighted avg       0.60      0.60      0.60      4290\n",
      "\n",
      "Mean Average Precision: 0.5611657155105432\n",
      "Area Under ROC Curve: 0.6018648018648018\n",
      "Precision:  0.6004597701149426\n",
      "Recall:  0.6088578088578088\n",
      "[LibLinear]Edge Operator: Hadamard\n",
      "TP:  1529\n",
      "TN:  696\n",
      "FP:  1449\n",
      "FN:  616\n",
      "F1: 0.5969158696076519\n",
      "[[ 696 1449]\n",
      " [ 616 1529]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.32      0.40      2145\n",
      "           1       0.51      0.71      0.60      2145\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      4290\n",
      "   macro avg       0.52      0.52      0.50      4290\n",
      "weighted avg       0.52      0.52      0.50      4290\n",
      "\n",
      "Mean Average Precision: 0.5095744864045737\n",
      "Area Under ROC Curve: 0.5186480186480187\n",
      "Precision:  0.5134318334452653\n",
      "Recall:  0.7128205128205128\n",
      "[LibLinear]Edge Operator: Weighted-L1\n",
      "TP:  1092\n",
      "TN:  1305\n",
      "FP:  840\n",
      "FN:  1053\n",
      "F1: 0.5356880058866813\n",
      "[[1305  840]\n",
      " [1053 1092]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.61      0.58      2145\n",
      "           1       0.57      0.51      0.54      2145\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      4290\n",
      "   macro avg       0.56      0.56      0.56      4290\n",
      "weighted avg       0.56      0.56      0.56      4290\n",
      "\n",
      "Mean Average Precision: 0.533201581027668\n",
      "Area Under ROC Curve: 0.5587412587412587\n",
      "Precision:  0.5652173913043478\n",
      "Recall:  0.509090909090909\n",
      "[LibLinear]Edge Operator: Weighted-L2\n",
      "TP:  1348\n",
      "TN:  1133\n",
      "FP:  1012\n",
      "FN:  797\n",
      "F1: 0.5984461709211987\n",
      "[[1133 1012]\n",
      " [ 797 1348]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.53      0.56      2145\n",
      "           1       0.57      0.63      0.60      2145\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      4290\n",
      "   macro avg       0.58      0.58      0.58      4290\n",
      "weighted avg       0.58      0.58      0.58      4290\n",
      "\n",
      "Mean Average Precision: 0.5447362806684841\n",
      "Area Under ROC Curve: 0.5783216783216782\n",
      "Precision:  0.5711864406779661\n",
      "Recall:  0.6284382284382284\n",
      "[LibLinear]Edge Operator: Concat\n",
      "TP:  1233\n",
      "TN:  1351\n",
      "FP:  794\n",
      "FN:  912\n",
      "F1: 0.5910834132310643\n",
      "[[1351  794]\n",
      " [ 912 1233]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.63      0.61      2145\n",
      "           1       0.61      0.57      0.59      2145\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      4290\n",
      "   macro avg       0.60      0.60      0.60      4290\n",
      "weighted avg       0.60      0.60      0.60      4290\n",
      "\n",
      "Mean Average Precision: 0.5622467320543295\n",
      "Area Under ROC Curve: 0.6023310023310023\n",
      "Precision:  0.6082881105081401\n",
      "Recall:  0.5748251748251748\n"
     ]
    }
   ],
   "source": [
    "for edge_operator in ['Average', 'Hadamard','Weighted-L1','Weighted-L2', 'Concat']:\n",
    "    # generate the training set\n",
    "    train_edges, train_edges_features_mtx, train_edges_labels = generate_train_set(graph_train, num_edge_sample, node_embeddings_training, edge_operator)\n",
    "    # generate the testing set\n",
    "    test_edges, test_edges_features_mtx, test_edges_labels = generate_test_set(graph_test, node_embeddings_testing, edge_operator)\n",
    "\n",
    "    LR_clf = build_clf(train_edges_features_mtx, train_edges_labels)\n",
    "\n",
    "    print(\"Edge Operator: {}\".format(edge_operator))\n",
    "    predict_edges_labels = pred_links(test_edges_features_mtx, LR_clf)\n",
    "    precision, recall = precision_recall(list(predict_edges_labels), list(test_edges_labels))\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
